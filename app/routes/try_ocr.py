# app/routes/try_ocr.py
# OCRæ¯”è¼ƒç”¨ãƒ«ãƒ¼ãƒˆ

from fastapi import APIRouter, UploadFile, File, Form, HTTPException
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from starlette.requests import Request
import os
import tempfile
import time
import csv
import re
from typing import List, Dict, Tuple

from app.services.ocr import OCREngineFactory
from db.handler import get_all_files

router = APIRouter()
templates = Jinja2Templates(directory="app/templates")

@router.get("/try_ocr", response_class=HTMLResponse)
async def try_ocr_page(request: Request):
    """OCRæ¯”è¼ƒãƒšãƒ¼ã‚¸"""
    # OCRãƒ•ã‚¡ã‚¯ãƒˆãƒªã‚’åˆæœŸåŒ–
    ocr_factory = OCREngineFactory()
    
    # åˆ©ç”¨å¯èƒ½ãªOCRã‚¨ãƒ³ã‚¸ãƒ³ã‚’å–å¾—
    available_engines_dict = ocr_factory.get_available_engines()
    engine_names = [engine_info['name'] for engine_id, engine_info in available_engines_dict.items() if engine_info['available']]
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    print(f"ğŸ” åˆ©ç”¨å¯èƒ½ãªOCRã‚¨ãƒ³ã‚¸ãƒ³: {engine_names}")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
    files = get_all_files()
    
    return templates.TemplateResponse("try_ocr.html", {
        "request": request,
        "engines": engine_names,
        "files": files
    })

@router.post("/api/try_ocr/process")
async def process_ocr(
    file: UploadFile = File(...),
    engine_name: str = Form(...),
    page_num: int = Form(0),
    use_correction: bool = Form(False)
):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã§OCRå‡¦ç†ã‚’å®Ÿè¡Œ"""
    try:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.filename)[1]) as temp_file:
            content = await file.read()
            temp_file.write(content)
            temp_path = temp_file.name
        
        try:
            # OCRãƒ•ã‚¡ã‚¯ãƒˆãƒªã‚’åˆæœŸåŒ–
            ocr_factory = OCREngineFactory()
            available_engines_dict = ocr_factory.get_available_engines()
            
            # ã‚¨ãƒ³ã‚¸ãƒ³åã‹ã‚‰IDã‚’ç‰¹å®š
            engine_id = None
            for eid, engine_info in available_engines_dict.items():
                if engine_info['name'] == engine_name and engine_info['available']:
                    engine_id = eid
                    break
            
            if not engine_id:
                raise HTTPException(status_code=404, detail=f"OCRã‚¨ãƒ³ã‚¸ãƒ³ '{engine_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            # å‡¦ç†æ™‚é–“ã‚’æ¸¬å®š
            start_time = time.time()
            
            # ãƒšãƒ¼ã‚¸ç•ªå·ã®å‡¦ç†
            if page_num == -1:  # å…¨ãƒšãƒ¼ã‚¸å‡¦ç†
                result = process_all_pages_with_factory(engine_id, temp_path, ocr_factory)
            else:
                result = ocr_factory.process_with_settings(engine_id, temp_path, page_num)
            
            # èª¤å­—ä¿®æ­£è¾æ›¸ã«ã‚ˆã‚‹ç½®æ›å‡¦ç†
            if use_correction and result["success"]:
                correction_dict = load_correction_dict()
                original_text = result["text"]  # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
                
                # çµ±åˆã•ã‚ŒãŸä¿®æ­£å‡¦ç†ã‚’å®Ÿè¡Œï¼ˆèª¤å­—ä¿®æ­£ + å…¨è§’â†’åŠè§’å¤‰æ›ï¼‰
                final_text, all_corrections = apply_all_corrections(original_text, correction_dict)
                
                # ç½®æ›ãŒè¡Œã‚ã‚ŒãŸå ´åˆ
                if all_corrections:
                    # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
                    result["original_text"] = original_text
                    # ä¿®æ­£å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š
                    result["text"] = final_text
                    # ç½®æ›æƒ…å ±ã‚’è¿½åŠ 
                    result["corrections"] = all_corrections
                    # HTMLãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—ã‚’è¿½åŠ ï¼ˆå…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ï¼‰
                    result["html_text"] = highlight_corrections(original_text, all_corrections)
                    # ç½®æ›æ•°ã‚’è¿½åŠ 
                    result["correction_count"] = len(all_corrections)
            
            processing_time = time.time() - start_time
            
            # å‡¦ç†æ™‚é–“ã‚’çµæœã«è¿½åŠ 
            result["processing_time"] = round(processing_time, 2)
            result["engine_name"] = engine_name
            result["page_num"] = page_num
            result["file_name"] = file.filename
            
            return result
            
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if os.path.exists(temp_path):
                os.unlink(temp_path)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# èª¤å­—ä¿®æ­£è¾æ›¸ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
def load_correction_dict() -> Dict[str, str]:
    """èª¤å­—ä¿®æ­£è¾æ›¸ã‚’èª­ã¿è¾¼ã‚€"""
    correction_dict = {}
    dict_path = "ocr/dic/ocr_word_mistakes.csv"
    
    if not os.path.exists(dict_path):
        return correction_dict
    
    try:
        with open(dict_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
            next(reader, None)
            for row in reader:
                if len(row) >= 2:
                    wrong, correct = row[0], row[1]
                    # ç©ºã®æ–‡å­—åˆ—ã¯ç„¡è¦–
                    if wrong and correct:
                        correction_dict[wrong] = correct
    except Exception as e:
        print(f"èª¤å­—ä¿®æ­£è¾æ›¸ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    return correction_dict

# ãƒ†ã‚­ã‚¹ãƒˆã«èª¤å­—ä¿®æ­£ã‚’é©ç”¨ã™ã‚‹é–¢æ•°ï¼ˆæ”¹å–„ç‰ˆï¼‰
def apply_corrections(text: str, correction_dict: Dict[str, str]) -> Tuple[str, List[Dict[str, str]]]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã«èª¤å­—ä¿®æ­£ã‚’é©ç”¨ã—ã€ç½®æ›æƒ…å ±ã‚’è¿”ã™ï¼ˆæ”¹å–„ç‰ˆï¼‰
    
    Returns:
        Tuple[str, List[Dict[str, str]]]: ä¿®æ­£å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã¨ç½®æ›æƒ…å ±ã®ãƒªã‚¹ãƒˆ
    """
    if not correction_dict or not text:
        return text, []
    
    # ç½®æ›æƒ…å ±ã‚’è¨˜éŒ²ã™ã‚‹ãƒªã‚¹ãƒˆ
    corrections = []
    
    # ç½®æ›ä½ç½®ã¨å†…å®¹ã‚’è¨˜éŒ²ã™ã‚‹ãƒªã‚¹ãƒˆï¼ˆä½ç½®æƒ…å ±ä»˜ãï¼‰
    replacements = []
    
    # è¾æ›¸ã®é †åºã‚’ç¶­æŒã—ã¦å‡¦ç†
    # å„ç½®æ›å¯¾è±¡ã«ã¤ã„ã¦å‡¦ç†
    for wrong, correct in correction_dict.items():
        correct = correction_dict[wrong]
        
        # ç¾åœ¨ã®ãƒ†ã‚­ã‚¹ãƒˆå†…ã§ç½®æ›å¯¾è±¡ã‚’æ¤œç´¢
        start_pos = 0
        while True:
            # ç½®æ›å¯¾è±¡ã®ä½ç½®ã‚’æ¤œç´¢
            pos = text.find(wrong, start_pos)
            if pos == -1:
                break
            
            # æ—¢ã«ç½®æ›äºˆå®šã®ç¯„å›²ã¨é‡è¤‡ã—ã¦ã„ãªã„ã‹ç¢ºèª
            overlap = False
            for repl in replacements:
                repl_start, repl_end = repl['start'], repl['end']
                # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                if not (pos >= repl_end or pos + len(wrong) <= repl_start):
                    overlap = True
                    break
            
            if not overlap:
                # ç½®æ›æƒ…å ±ã‚’è¨˜éŒ²
                replacements.append({
                    'start': pos,
                    'end': pos + len(wrong),
                    'wrong': wrong,
                    'correct': correct
                })
                corrections.append({
                    "wrong": wrong,
                    "correct": correct,
                    "position": pos
                })
            
            # æ¬¡ã®æ¤œç´¢é–‹å§‹ä½ç½®ã‚’æ›´æ–°
            start_pos = pos + 1
    
    # ç½®æ›ä½ç½®ã§ã‚½ãƒ¼ãƒˆï¼ˆå¾Œã‚ã‹ã‚‰å‡¦ç†ã™ã‚‹ã“ã¨ã§ä½ç½®ã®ãšã‚Œã‚’é˜²ãï¼‰
    replacements.sort(key=lambda x: x['start'], reverse=True)
    
    # ç½®æ›ã‚’å®Ÿè¡Œ
    result_text = text
    for repl in replacements:
        start, end = repl['start'], repl['end']
        correct = repl['correct']
        # æ–‡å­—åˆ—ã®è©²å½“éƒ¨åˆ†ã‚’ç½®æ›
        result_text = result_text[:start] + correct + result_text[end:]
    
    return result_text, corrections

# é‡è¤‡ã—ãŸé–¢æ•°ã‚’å‰Šé™¤ï¼ˆapply_all_correctionsé–¢æ•°ã‚’ä½¿ç”¨ï¼‰

# çµ±åˆã•ã‚ŒãŸä¿®æ­£å‡¦ç†é–¢æ•°
def apply_all_corrections(text: str, correction_dict: Dict[str, str]) -> Tuple[str, List[Dict[str, str]]]:
    """
    èª¤å­—ä¿®æ­£ã¨å…¨è§’â†’åŠè§’å¤‰æ›ã‚’çµ±åˆã—ã¦å®Ÿè¡Œ
    
    Returns:
        Tuple[str, List[Dict[str, str]]]: ä¿®æ­£å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã¨ä¿®æ­£æƒ…å ±ã®ãƒªã‚¹ãƒˆ
    """
    if not text:
        return text, []
    
    # å…¨è§’â†’åŠè§’ã®å¤‰æ›ãƒãƒƒãƒ—
    fullwidth_map = {
        # æ•°å­—
        'ï¼': '0', 'ï¼‘': '1', 'ï¼’': '2', 'ï¼“': '3', 'ï¼”': '4',
        'ï¼•': '5', 'ï¼–': '6', 'ï¼—': '7', 'ï¼˜': '8', 'ï¼™': '9',
        # è‹±å­—ï¼ˆå¤§æ–‡å­—ï¼‰
        'ï¼¡': 'A', 'ï¼¢': 'B', 'ï¼£': 'C', 'ï¼¤': 'D', 'ï¼¥': 'E',
        'ï¼¦': 'F', 'ï¼§': 'G', 'ï¼¨': 'H', 'ï¼©': 'I', 'ï¼ª': 'J',
        'ï¼«': 'K', 'ï¼¬': 'L', 'ï¼­': 'M', 'ï¼®': 'N', 'ï¼¯': 'O',
        'ï¼°': 'P', 'ï¼±': 'Q', 'ï¼²': 'R', 'ï¼³': 'S', 'ï¼´': 'T',
        'ï¼µ': 'U', 'ï¼¶': 'V', 'ï¼·': 'W', 'ï¼¸': 'X', 'ï¼¹': 'Y', 'ï¼º': 'Z',
        # è‹±å­—ï¼ˆå°æ–‡å­—ï¼‰
        'ï½': 'a', 'ï½‚': 'b', 'ï½ƒ': 'c', 'ï½„': 'd', 'ï½…': 'e',
        'ï½†': 'f', 'ï½‡': 'g', 'ï½ˆ': 'h', 'ï½‰': 'i', 'ï½Š': 'j',
        'ï½‹': 'k', 'ï½Œ': 'l', 'ï½': 'm', 'ï½': 'n', 'ï½': 'o',
        'ï½': 'p', 'ï½‘': 'q', 'ï½’': 'r', 'ï½“': 's', 'ï½”': 't',
        'ï½•': 'u', 'ï½–': 'v', 'ï½—': 'w', 'ï½˜': 'x', 'ï½™': 'y', 'ï½š': 'z',
        # è¨˜å·
        'ï¼': '.', 'ï¼Œ': ',', 'ï¼š': ':', 'ï¼›': ';', 'ï¼Ÿ': '?',
        'ï¼': '!', 'ï¼ˆ': '(', 'ï¼‰': ')', 'ï¼»': '[', 'ï¼½': ']',
        'ï½›': '{', 'ï½': '}', 'ï¼‹': '+', 'ï¼': '-', 'ï¼Š': '*',
        'ï¼': '/', 'ï¼': '=', 'ï¼œ': '<', 'ï¼': '>', 'ï¼ ': '@',
        'ï¼ƒ': '#', 'ï¼…': '%', 'ï¼†': '&', 'ï½œ': '|', 'ï¼¼': '\\',
        'ï¼¾': '^', 'ï¼¿': '_', 'ï½€': '`', 'ï½': '~', 'ã€€': ' ',  # å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹
        # é•·éŸ³è¨˜å·ãƒ»ãƒã‚¤ãƒ•ãƒ³é¡ï¼ˆæŠ€è¡“æ–‡æ›¸ã§ã‚ˆãä½¿ã‚ã‚Œã‚‹ï¼‰
        'â€•': '-',  # å…¨è§’ãƒ€ãƒƒã‚·ãƒ¥ï¼ˆem dashï¼‰
        'â€': '-',  # ãƒã‚¤ãƒ•ãƒ³
        'â€“': '-',  # en dash
        'â€”': '-'   # em dash
        # æ³¨æ„: 'ãƒ¼'ï¼ˆã‚«ã‚¿ã‚«ãƒŠé•·éŸ³è¨˜å·ï¼‰ã¯æ–‡è„ˆåˆ¤å®šã§å‡¦ç†
    }
    
    # çµ±åˆã•ã‚ŒãŸå¤‰æ›è¾æ›¸ã‚’ä½œæˆï¼ˆèª¤å­—ä¿®æ­£ + å…¨è§’â†’åŠè§’ï¼‰
    combined_dict = {}
    
    # 1. èª¤å­—ä¿®æ­£è¾æ›¸ã‚’è¿½åŠ 
    for wrong, correct in correction_dict.items():
        combined_dict[wrong] = {"correct": correct, "type": "correction"}
    
    # 2. å…¨è§’â†’åŠè§’å¤‰æ›ã‚’è¿½åŠ 
    for fullwidth, halfwidth in fullwidth_map.items():
        combined_dict[fullwidth] = {"correct": halfwidth, "type": "normalization"}
    
    # ä¿®æ­£æƒ…å ±ã‚’è¨˜éŒ²ã™ã‚‹ãƒªã‚¹ãƒˆ
    corrections = []
    
    # ç½®æ›ä½ç½®ã¨å†…å®¹ã‚’è¨˜éŒ²ã™ã‚‹ãƒªã‚¹ãƒˆï¼ˆä½ç½®æƒ…å ±ä»˜ãï¼‰
    replacements = []
    
    # å„å¤‰æ›å¯¾è±¡ã«ã¤ã„ã¦å‡¦ç†
    for wrong, info in combined_dict.items():
        correct = info["correct"]
        correction_type = info["type"]
        
        start_pos = 0
        while True:
            # å¤‰æ›å¯¾è±¡ã®ä½ç½®ã‚’æ¤œç´¢
            pos = text.find(wrong, start_pos)
            if pos == -1:
                break
            
            # ãƒ‡ãƒãƒƒã‚°: ãƒ€ãƒƒã‚·ãƒ¥ç³»æ–‡å­—ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚’å‡ºåŠ›
            if wrong in ['â€”', 'â€•', 'â€', 'â€“', 'ãƒ¼']:
                print(f"ğŸ” Found '{wrong}' (U+{ord(wrong):04X}) at position {pos}")
            
            # æ—¢ã«å¤‰æ›äºˆå®šã®ç¯„å›²ã¨é‡è¤‡ã—ã¦ã„ãªã„ã‹ç¢ºèª
            overlap = False
            for repl in replacements:
                repl_start, repl_end = repl['start'], repl['end']
                # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                if not (pos >= repl_end or pos + len(wrong) <= repl_start):
                    overlap = True
                    break
            
            if not overlap:
                # å¤‰æ›æƒ…å ±ã‚’è¨˜éŒ²
                replacements.append({
                    'start': pos,
                    'end': pos + len(wrong),
                    'wrong': wrong,
                    'correct': correct,
                    'type': correction_type
                })
                corrections.append({
                    "wrong": wrong,
                    "correct": correct,
                    "position": pos,
                    "type": correction_type
                })
            
            # æ¬¡ã®æ¤œç´¢é–‹å§‹ä½ç½®ã‚’æ›´æ–°
            start_pos = pos + 1
    
    # ã‚«ã‚¿ã‚«ãƒŠé•·éŸ³è¨˜å·ã€Œãƒ¼ã€ã®æ–‡è„ˆåˆ¤å®šå‡¦ç†
    katakana_dash_replacements = []
    start_pos = 0
    while True:
        pos = text.find('ãƒ¼', start_pos)
        if pos == -1:
            break
        
        # å‰å¾Œã®æ–‡å­—ã‚’ãƒã‚§ãƒƒã‚¯
        prev_char = text[pos - 1] if pos > 0 else ''
        next_char = text[pos + 1] if pos < len(text) - 1 else ''
        
        # è‹±æ•°å­—ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹é–¢æ•°
        def is_alphanumeric(char):
            return char.isalnum() or char in 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½šï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™'
        
        # ã‚«ã‚¿ã‚«ãƒŠã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹é–¢æ•°
        def is_katakana(char):
            return '\u30A0' <= char <= '\u30FF'
        
        # ã²ã‚‰ãŒãªã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹é–¢æ•°
        def is_hiragana(char):
            return '\u3040' <= char <= '\u309F'
        
        # æ—¥æœ¬èªæ–‡å­—ï¼ˆã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»æ¼¢å­—ï¼‰ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹é–¢æ•°
        def is_japanese(char):
            return (is_hiragana(char) or 
                   is_katakana(char) or 
                   '\u4E00' <= char <= '\u9FAF' or  # æ¼¢å­—
                   '\u3400' <= char <= '\u4DBF')    # æ¼¢å­—æ‹¡å¼µA
        
        # å‰å¾Œã®æ–‡å­—ã®ç¨®é¡ã‚’åˆ¤å®š
        prev_is_alphanumeric = is_alphanumeric(prev_char)
        next_is_alphanumeric = is_alphanumeric(next_char)
        prev_is_japanese = is_japanese(prev_char)
        next_is_japanese = is_japanese(next_char)
        
        # å¤‰æ›æ¡ä»¶ï¼šå‰å¾Œã®ã©ã¡ã‚‰ã‹ãŒè‹±æ•°å­—ã§ã€ã‹ã¤ä¸¡æ–¹ãŒæ—¥æœ¬èªæ–‡å­—ã§ã¯ãªã„å ´åˆã®ã¿å¤‰æ›
        should_convert = ((prev_is_alphanumeric or next_is_alphanumeric) and 
                         not (prev_is_japanese and next_is_japanese))
        
        if should_convert:
            # æ—¢å­˜ã®ç½®æ›ã¨é‡è¤‡ã—ã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
            overlap = False
            for repl in replacements:
                if not (pos >= repl['end'] or pos + 1 <= repl['start']):
                    overlap = True
                    break
            
            if not overlap:
                katakana_dash_replacements.append({
                    'start': pos,
                    'end': pos + 1,
                    'wrong': 'ãƒ¼',
                    'correct': '-',
                    'type': 'normalization'
                })
                corrections.append({
                    "wrong": 'ãƒ¼',
                    "correct": '-',
                    "position": pos,
                    "type": 'normalization'
                })
                print(f"ğŸ” Context-based conversion: 'ãƒ¼' (U+30FC) at position {pos} -> '-' (prev: '{prev_char}', next: '{next_char}')")
        
        start_pos = pos + 1
    
    # ã‚«ã‚¿ã‚«ãƒŠé•·éŸ³è¨˜å·ã®æ–‡è„ˆåˆ¤å®šã«ã‚ˆã‚‹ç½®æ›ã‚’è¿½åŠ 
    replacements.extend(katakana_dash_replacements)
    
    # å¤‰æ›ä½ç½®ã§ã‚½ãƒ¼ãƒˆï¼ˆå¾Œã‚ã‹ã‚‰å‡¦ç†ã™ã‚‹ã“ã¨ã§ä½ç½®ã®ãšã‚Œã‚’é˜²ãï¼‰
    replacements.sort(key=lambda x: x['start'], reverse=True)
    
    # å¤‰æ›ã‚’å®Ÿè¡Œ
    result_text = text
    for repl in replacements:
        start, end = repl['start'], repl['end']
        correct = repl['correct']
        # æ–‡å­—åˆ—ã®è©²å½“éƒ¨åˆ†ã‚’å¤‰æ›
        result_text = result_text[:start] + correct + result_text[end:]
    
    return result_text, corrections

# HTMLã§ç½®æ›ç®‡æ‰€ã‚’ãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—ã™ã‚‹é–¢æ•°ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰
def highlight_corrections(original_text: str, corrections: List[Dict[str, str]]) -> str:
    """
    ç½®æ›ç®‡æ‰€ã‚’èµ¤æ–‡å­—ã§ãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—ã—ãŸHTMLã‚’ç”Ÿæˆï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰
    original_text: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆç½®æ›å‰ï¼‰
    corrections: ç½®æ›æƒ…å ±ã®ãƒªã‚¹ãƒˆï¼ˆpositionæƒ…å ±ã‚’å«ã‚€ï¼‰
    """
    if not corrections:
        # ç½®æ›ãŒãªã„å ´åˆã¯é€šå¸¸ã®HTMLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã®ã¿
        html_text = original_text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
        return html_text.replace("\n", "<br>")
    
    # ç½®æ›æƒ…å ±ã‚’ä½ç½®ã§ã‚½ãƒ¼ãƒˆï¼ˆå‰ã‹ã‚‰å‡¦ç†ï¼‰
    sorted_corrections = sorted(corrections, key=lambda x: x.get('position', 0))
    
    # æ–‡å­—åˆ—ã‚’åˆ†å‰²ã—ã¦HTMLã‚’æ§‹ç¯‰
    result_parts = []
    last_pos = 0
    
    for correction in sorted_corrections:
        wrong = correction['wrong']
        correct = correction['correct']
        position = correction.get('position', 0)
        
        # å‰ã®éƒ¨åˆ†ï¼ˆç½®æ›ã•ã‚Œãªã„éƒ¨åˆ†ï¼‰ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã¦è¿½åŠ 
        before_part = original_text[last_pos:position]
        escaped_before = before_part.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
        result_parts.append(escaped_before)
        
        # ç½®æ›éƒ¨åˆ†ã‚’èµ¤å­—ã§ãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—ï¼ˆç¨®é¡ã«å¿œã˜ã¦è‰²ã‚’å¤‰ãˆã‚‹ï¼‰
        escaped_wrong = wrong.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
        escaped_correct = correct.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
        
        # æ­£è¦åŒ–ï¼ˆå…¨è§’â†’åŠè§’ï¼‰ã®å ´åˆã¯é’è‰²ã€èª¤å­—ä¿®æ­£ã¯èµ¤è‰²
        if correction.get('type') == 'normalization':
            marked_part = f'<span style="color:blue; font-weight:bold;" title="å…¨è§’â†’åŠè§’: {escaped_wrong}">{escaped_correct}</span>'
        else:
            marked_part = f'<span style="color:red; font-weight:bold;" title="ä¿®æ­£å‰: {escaped_wrong}">{escaped_correct}</span>'
        
        result_parts.append(marked_part)
        
        # æ¬¡ã®é–‹å§‹ä½ç½®ã‚’æ›´æ–°ï¼ˆå…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã§ã®ä½ç½®ï¼‰
        last_pos = position + len(wrong)
    
    # æ®‹ã‚Šã®éƒ¨åˆ†ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã¦è¿½åŠ 
    remaining_part = original_text[last_pos:]
    escaped_remaining = remaining_part.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
    result_parts.append(escaped_remaining)
    
    # çµåˆã—ã¦HTMLã‚’ç”Ÿæˆ
    html_text = ''.join(result_parts)
    
    # æ”¹è¡Œã‚’HTMLã®æ”¹è¡Œã‚¿ã‚°ã«å¤‰æ›
    html_text = html_text.replace("\n", "<br>")
    
    return html_text

@router.post("/api/try_ocr/process_file")
async def process_ocr_file(
    file: UploadFile = File(...),
    engine_name: str = Form(...),
    page_num: int = Form(0),
    use_correction: bool = Form(False)
):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã§OCRå‡¦ç†ã‚’å®Ÿè¡Œ"""
    try:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.filename)[1]) as temp_file:
            content = await file.read()
            temp_file.write(content)
            temp_path = temp_file.name
        
        try:
            # OCRãƒ•ã‚¡ã‚¯ãƒˆãƒªã‚’åˆæœŸåŒ–
            ocr_factory = OCREngineFactory()
            available_engines_dict = ocr_factory.get_available_engines()
            
            # ã‚¨ãƒ³ã‚¸ãƒ³åã‹ã‚‰IDã‚’ç‰¹å®š
            engine_id = None
            for eid, engine_info in available_engines_dict.items():
                if engine_info['name'] == engine_name and engine_info['available']:
                    engine_id = eid
                    break
            
            if not engine_id:
                raise HTTPException(status_code=404, detail=f"OCRã‚¨ãƒ³ã‚¸ãƒ³ '{engine_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            # å‡¦ç†æ™‚é–“ã‚’æ¸¬å®š
            start_time = time.time()
            
            # ãƒšãƒ¼ã‚¸ç•ªå·ã®å‡¦ç†
            if page_num == -1:  # å…¨ãƒšãƒ¼ã‚¸å‡¦ç†
                result = process_all_pages_with_factory(engine_id, temp_path, ocr_factory)
            else:
                result = ocr_factory.process_with_settings(engine_id, temp_path, page_num)
            
            # èª¤å­—ä¿®æ­£è¾æ›¸ã«ã‚ˆã‚‹ç½®æ›å‡¦ç†
            if use_correction and result["success"]:
                correction_dict = load_correction_dict()
                original_text = result["text"]  # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
                
                # çµ±åˆã•ã‚ŒãŸä¿®æ­£å‡¦ç†ã‚’å®Ÿè¡Œï¼ˆèª¤å­—ä¿®æ­£ + å…¨è§’â†’åŠè§’å¤‰æ›ï¼‰
                final_text, all_corrections = apply_all_corrections(original_text, correction_dict)
                
                # ç½®æ›ãŒè¡Œã‚ã‚ŒãŸå ´åˆ
                if all_corrections:
                    # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
                    result["original_text"] = original_text
                    # ä¿®æ­£å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š
                    result["text"] = final_text
                    # ç½®æ›æƒ…å ±ã‚’è¿½åŠ 
                    result["corrections"] = all_corrections
                    # HTMLãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—ã‚’è¿½åŠ ï¼ˆå…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ï¼‰
                    result["html_text"] = highlight_corrections(original_text, all_corrections)
                    # ç½®æ›æ•°ã‚’è¿½åŠ 
                    result["correction_count"] = len(all_corrections)
            
            processing_time = time.time() - start_time
            
            # å‡¦ç†æ™‚é–“ã‚’çµæœã«è¿½åŠ 
            result["processing_time"] = round(processing_time, 2)
            result["engine_name"] = engine_name
            result["page_num"] = page_num
            result["file_name"] = file.filename
            
            return result
            
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if os.path.exists(temp_path):
                os.unlink(temp_path)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

def process_all_pages(engine, file_path: str) -> dict:
    """å…¨ãƒšãƒ¼ã‚¸ã‚’OCRå‡¦ç†ï¼ˆæ—§ç‰ˆãƒ»äº’æ›æ€§ã®ãŸã‚æ®‹å­˜ï¼‰"""
    import fitz
    
    try:
        doc = fitz.open(file_path)
        total_pages = len(doc)
        doc.close()
        
        all_text = []
        total_confidence = 0
        confidence_count = 0
        
        for page_num in range(total_pages):
            result = engine.process(file_path, page_num)
            if result["success"]:
                all_text.append(f"=== ãƒšãƒ¼ã‚¸ {page_num + 1} ===")
                all_text.append(result["text"])
                all_text.append("")  # ç©ºè¡Œ
                
                if result.get("confidence"):
                    total_confidence += result["confidence"]
                    confidence_count += 1
        
        avg_confidence = total_confidence / confidence_count if confidence_count > 0 else None
        
        return {
            "success": True,
            "text": "\n".join(all_text),
            "confidence": avg_confidence,
            "pages_processed": total_pages
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"å…¨ãƒšãƒ¼ã‚¸å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}",
            "text": ""
        }

def process_all_pages_with_factory(engine_id: str, file_path: str, ocr_factory: OCREngineFactory) -> dict:
    """å…¨ãƒšãƒ¼ã‚¸ã‚’OCRå‡¦ç†ï¼ˆçµ±ä¸€ã•ã‚ŒãŸOCRã‚µãƒ¼ãƒ“ã‚¹ä½¿ç”¨ï¼‰"""
    import fitz
    
    try:
        doc = fitz.open(file_path)
        total_pages = len(doc)
        doc.close()
        
        all_text = []
        total_confidence = 0
        confidence_count = 0
        
        for page_num in range(total_pages):
            result = ocr_factory.process_with_settings(engine_id, file_path, page_num)
            if result["success"]:
                all_text.append(f"=== ãƒšãƒ¼ã‚¸ {page_num + 1} ===")
                all_text.append(result["text"])
                all_text.append("")  # ç©ºè¡Œ
                
                if result.get("confidence"):
                    total_confidence += result["confidence"]
                    confidence_count += 1
        
        avg_confidence = total_confidence / confidence_count if confidence_count > 0 else None
        
        return {
            "success": True,
            "text": "\n".join(all_text),
            "confidence": avg_confidence,
            "pages_processed": total_pages
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"å…¨ãƒšãƒ¼ã‚¸å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}",
            "text": ""
        }

@router.get("/api/try_ocr/engines")
async def get_engines():
    """åˆ©ç”¨å¯èƒ½ãªOCRã‚¨ãƒ³ã‚¸ãƒ³ä¸€è¦§ã‚’å–å¾—"""
    ocr_factory = OCREngineFactory()
    available_engines_dict = ocr_factory.get_available_engines()
    return [
        {
            "name": engine_info['name'],
            "available": engine_info['available']
        }
        for engine_id, engine_info in available_engines_dict.items()
    ]

@router.get("/api/try_ocr/engine_parameters/{engine_name}")
async def get_engine_parameters(engine_name: str):
    """æŒ‡å®šã•ã‚ŒãŸOCRã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©ã‚’å–å¾—"""
    try:
        ocr_factory = OCREngineFactory()
        available_engines_dict = ocr_factory.get_available_engines()
        
        for engine_id, engine_info in available_engines_dict.items():
            if engine_info['name'] == engine_name and engine_info['available']:
                return {
                    "engine_name": engine_name,
                    "parameters": engine_info['parameters']
                }
        raise ValueError(f"OCRã‚¨ãƒ³ã‚¸ãƒ³ '{engine_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))