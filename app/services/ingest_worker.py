# REM: app/services/ingest_worker.py @2025-07-18 00:00 UTC +9
"""
1ãƒ•ã‚¡ã‚¤ãƒ«åˆ†ã®ã‚¤ãƒ³ã‚¸ã‚§ã‚¹ãƒˆå‡¦ç†æœ¬ä½“ã€‚
StreamingResponse å´ã¸ dict ã‚’é€æ¬¡ yield ã—ã€SSE ã§é€å‡ºã—ã¦ã‚‚ã‚‰ã†ã€‚
"""

# REM: â”€â”€ æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import functools, time, unicodedata, os
from typing import Dict, Generator, List
import logging

# REM: â”€â”€ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…±é€š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from src.config import OLLAMA_MODEL

# REM: â”€â”€ I/Oãƒ»LLMãƒ»DB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from fileio.extractor     import extract_text_by_extension
from fileio.file_embedder import embed_and_insert
from llm.chunker          import split_into_chunks
from llm.refiner          import (
    normalize_empty_lines,
    refine_text_with_llm,
    build_prompt,
)
from ocr.spellcheck       import correct_text
from db.handler           import (
    insert_file_full,
    update_file_text,
    update_file_status,
    get_file_text,
)

# REM: â”€â”€ å®šæ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOK_LIMIT    = 8192
CHUNK_SIZE   = 500
OVERLAP_SIZE = 50
LOGGER       = logging.getLogger("ingest_worker")

# REM: è‹±èªãƒ†ãƒ³ãƒ—ãƒ¬èª¤åæ˜ ãªã©ã«è©²å½“ã™ã‚‹å…¸å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆloweræ¯”è¼ƒå‰æï¼‰
TEMPLATE_PATTERNS = [
    "certainly", "please provide", "reformat", "i will help",
    "note that this is a translation", "based on your ocr output"
]


# REM: process_file â”€ 1ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã‚¤ãƒ™ãƒ³ãƒˆã‚’ yield
def process_file(
    *,
    file_path: str,
    file_name: str,
    index: int,
    total_files: int,
    refine_prompt_key: str,
    refine_prompt_text: str = None,        # REM: è¿½åŠ 
    embed_models: List[str],
    overwrite_existing: bool,
    quality_threshold: float,
    llm_timeout_sec: int,
    abort_flag: Dict[str, bool],
) -> Generator[Dict, None, None]:
    t0 = time.perf_counter()

    # â”€â”€ â‘  DB ä»®ç™»éŒ² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        file_id = insert_file_full(file_path, "", "", 0.0)
    except Exception as exc:
        LOGGER.exception("insert_file_full")
        yield {"file": file_name, "step": "DBç™»éŒ²å¤±æ•—", "detail": str(exc)}
        return

    yield {
        "file": file_name,
        "file_id": file_id,
        "step": "ãƒ•ã‚¡ã‚¤ãƒ«ç™»éŒ²å®Œäº†",
        "index": index,
        "total": total_files,
    }

    # â”€â”€ â‘¡ ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    yield {"file": file_name, "step": "ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºé–‹å§‹"}
    
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‚’ç¢ºèª
        ext = os.path.splitext(file_path)[1].lower()
        
        if ext == ".pdf":
            # PDFã®å ´åˆã¯ãƒšãƒ¼ã‚¸ã”ã¨ã®é€²æ—ã‚’è¡¨ç¤º
            from fileio.extractor import extract_text_from_pdf_with_progress
            pages = None
            
            for event in extract_text_from_pdf_with_progress(file_path):
                if "progress" in event:
                    # ãƒšãƒ¼ã‚¸ã”ã¨ã®é€²æ—ã‚’Webç”»é¢ã«è¡¨ç¤º
                    yield {"file": file_name, "step": f"ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºä¸­: {event['progress']}"}
                elif "result" in event:
                    # æœ€çµ‚çµæœã‚’å–å¾—
                    pages = event["result"]
                    break
        elif ext == ".eml":
            # EMLãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯å°‚ç”¨å‡¦ç†
            from fileio.extractor import extract_text_from_eml
            pages = extract_text_from_eml(file_path)
            yield {"file": file_name, "step": "EMLãƒ•ã‚¡ã‚¤ãƒ«æŠ½å‡ºä¸­..."}
        else:
            # ãã®ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã¯å¾“æ¥é€šã‚Š
            pages = extract_text_by_extension(file_path)
            yield {"file": file_name, "step": "ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºä¸­..."}
            
    except Exception as exc:
        LOGGER.exception("extract_text_by_extension")
        update_file_status(file_id, status="error", note=str(exc))
        yield {"file": file_name, "step": "ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå¤±æ•—", "detail": str(exc)}
        return

    if not pages:
        update_file_status(file_id, status="error", note="no text")
        yield {"file": file_name, "step": "ãƒ†ã‚­ã‚¹ãƒˆç„¡ã—"}
        return

    yield {"file": file_name, "step": "ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå®Œäº†", "pages": len(pages)}

    # â”€â”€ â‘¢ å…¨æ–‡ç”Ÿæˆ â†’ raw_text ä¿å­˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    page_blocks = [
        normalize_empty_lines(correct_text(unicodedata.normalize("NFKC", p)))
        for p in pages
    ]
    full_text = "\n\n".join(page_blocks)
    update_file_text(file_id, raw_text=full_text)

    token_est = int(len(full_text) * 1.6)
    use_page  = token_est > TOK_LIMIT
    unit_iter = enumerate(page_blocks, 1) if use_page else [("all", full_text)]

    refined_pages: List[str] = []
    file_min_score: float = 1.0

    # â”€â”€ â‘£ LLM æ•´å½¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # EMLãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯æ®µè½åˆ¥æ•´å½¢å‡¦ç†ã‚’é©ç”¨
    ext = os.path.splitext(file_path)[1].lower()
    if ext == ".eml":
        yield {"file": file_name, "step": "ğŸ“§ EMLãƒ•ã‚¡ã‚¤ãƒ«æ®µè½æ•´å½¢ãƒ¢ãƒ¼ãƒ‰é©ç”¨"}
        
        # å¼•ç”¨è¨˜å·ã®é™¤å»ã¨æ®µè½åˆ†å‰²
        corrected = full_text.replace(">>", "").replace("> >", "").replace("> ", "")
        paragraphs = [p.strip() for p in corrected.split("\n\n") if len(p.strip()) > 30]
        
        yield {"file": file_name, "step": f"æ®µè½åˆ†å‰²å®Œäº†: {len(paragraphs)}å€‹ã®æ®µè½"}
        
        refined_parts = []
        for i, para in enumerate(paragraphs):
            if abort_flag["flag"]:
                return
                
            yield {"file": file_name, "step": f"ğŸ“‘ æ®µè½ {i+1}/{len(paragraphs)} ã‚’æ•´å½¢ä¸­..."}
            
            try:
                # æ®µè½ã”ã¨ã«LLMæ•´å½¢
                refined, _, score, _ = refine_text_with_llm(
                    para, 
                    model=OLLAMA_MODEL,
                    force_lang=refine_prompt_key,
                    abort_flag=abort_flag
                )
                
                # ä¸æ­£ãªæ•´å½¢çµæœã‚’ãƒã‚§ãƒƒã‚¯
                if _is_invalid_llm_output(refined):
                    yield {"file": file_name, "step": f"âš ï¸ æ®µè½ {i+1}: ä¸æ­£ãªæ•´å½¢çµæœã‚’ã‚¹ã‚­ãƒƒãƒ—"}
                    continue
                    
                refined_parts.append(refined)
                file_min_score = min(file_min_score, score)
                
                yield {"file": file_name, "step": f"âœ… æ®µè½ {i+1}/{len(paragraphs)} æ•´å½¢å®Œäº†"}
                
            except Exception as e:
                LOGGER.warning(f"æ®µè½ {i+1} æ•´å½¢å¤±æ•—: {e}")
                yield {"file": file_name, "step": f"âš ï¸ æ®µè½ {i+1} æ•´å½¢å¤±æ•—: {e}"}
                continue
        
        if refined_parts:
            refined_pages = ["\n\n".join(refined_parts)]
            yield {"file": file_name, "step": f"EMLæ®µè½æ•´å½¢å®Œäº†: {len(refined_parts)}æ®µè½ã‚’çµ±åˆ"}
        else:
            yield {"file": file_name, "step": "âš ï¸ æœ‰åŠ¹ãªæ®µè½ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"}
            refined_pages = [full_text]  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    else:
        # é€šå¸¸ã®ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
        for pg, block in unit_iter:
            if abort_flag["flag"]:
                return

            label = f"page{pg}" if use_page else "all"
            # REM: ç·¨é›†ãƒšã‚¤ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ã†ï¼ˆ{TEXT}ç½®æ›ã®ã¿ï¼‰
            if refine_prompt_text:
                cleaned = normalize_empty_lines(correct_text(block))
                prompt_text = refine_prompt_text.replace("{TEXT}", cleaned)
            else:
                prompt_text = build_prompt(block, refine_prompt_key)

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¦‹å‡ºã—ï¼ˆå…¨æ–‡ç”¨ï¼‰
            yield {"file": file_name, "step": f"ä½¿ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡ part:{label}"}
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡
            yield {
                "file":    file_name,
                "step":    "prompt_text",
                "part":    label,
                "content": prompt_text,
            }

            # é€²è¡Œä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆâ€»å»ƒæ­¢ã—ãªã„ï¼‰
            yield {"file": file_name, "step": f"LLMæ•´å½¢ä¸­ part:{label}"}

            job = functools.partial(
                refine_text_with_llm,
                block,
                model=OLLAMA_MODEL,
                force_lang=refine_prompt_key,
                abort_flag=abort_flag,
            )
            try:
                refined, _, score, _ = job() if not llm_timeout_sec else \
                    _run_with_timeout(job, llm_timeout_sec)
            except TimeoutError:
                update_file_status(file_id, status="error", note="llm timeout")
                yield {"file": file_name, "step": "LLMã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ", "part": label}
                return
            except Exception as exc:
                LOGGER.exception("LLM refine")
                update_file_status(file_id, status="error", note=str(exc))
                yield {"file": file_name, "step": "LLMæ•´å½¢å¤±æ•—", "detail": str(exc)}
                return

            refined_pages.append(refined)
            file_min_score = min(file_min_score, score)

            # æ•´å½¢çµæœè¦‹å‡ºã—ï¼ˆå…¨æ–‡ï¼‰
            yield {"file": file_name, "step": f"LLMæ•´å½¢çµæœå…¨æ–‡ part:{label}"}
            # æ•´å½¢çµæœå…¨æ–‡
            yield {
                "file":    file_name,
                "step":    "refined_text",
                "part":    label,
                "content": refined,
            }

    if abort_flag["flag"] or not refined_pages:
        return

    # â”€â”€ â‘¤ ãƒãƒ£ãƒ³ã‚¯åˆ†å‰² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    final_text = "\n\n".join(refined_pages)
    chunks = split_into_chunks(final_text, chunk_size=CHUNK_SIZE, overlap=OVERLAP_SIZE)
    yield {"file": file_name, "step": f"ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²å®Œäº† chunks={len(chunks)}"}

    # â”€â”€ â‘¥ ãƒ™ã‚¯ãƒˆãƒ«åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    embed_job = functools.partial(
        embed_and_insert,
        texts=chunks,
        file_name=file_path,
        model_keys=embed_models,
        quality_score=file_min_score,
        file_id=file_id,
    )
    try:
        embed_job()
        yield {"file": file_name, "step": "ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Œäº†"}
    except Exception as exc:
        LOGGER.exception("embed_and_insert")
        update_file_status(file_id, status="error", note=str(exc))
        yield {"file": file_name, "step": "ãƒ™ã‚¯ãƒˆãƒ«åŒ–å¤±æ•—", "detail": str(exc)}
        return

    # â”€â”€ â‘¦ refined_text ä¿å­˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    cur = get_file_text(file_id) or {}
    need_upd = (
        overwrite_existing or not cur.get("refined_text") or
        (cur.get("quality_score") or 0.0) < quality_threshold or
        file_min_score < (cur.get("quality_score") or 1.0)
    )
    if need_upd:
        update_file_text(file_id, refined_text=final_text, quality_score=file_min_score)
        yield {"file": file_name, "step": "å…¨æ–‡ä¿å­˜å®Œäº†ï¼ˆä¸Šæ›¸ãå®Ÿæ–½ï¼‰"}
    else:
        yield {"file": file_name, "step": "å…¨æ–‡ä¿å­˜ã‚¹ã‚­ãƒƒãƒ—"}

    update_file_status(file_id, status="done")
    yield {
        "file": file_name,
        "step": "file_done",
        "elapsed": round(time.perf_counter() - t0, 2),
    }


# â”€â”€ _is_invalid_llm_output â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _is_invalid_llm_output(text: str) -> bool:
    """LLMæ•´å½¢å¾Œã®å‡ºåŠ›ãŒãƒ†ãƒ³ãƒ—ãƒ¬ãƒ»è‹±èªãƒ»ç„¡æ„å‘³ãªã©ã®ä¸æ­£å†…å®¹ã‹ã‚’åˆ¤å®š"""
    try:
        from langdetect import detect
    except ImportError:
        # langdetectãŒãªã„å ´åˆã¯åŸºæœ¬ãƒã‚§ãƒƒã‚¯ã®ã¿
        if len(text.strip()) < 30:
            return True
        lower = text.lower()
        return any(p in lower for p in TEMPLATE_PATTERNS)

    if len(text.strip()) < 30:
        return True

    lower = text.lower()
    if any(p in lower for p in TEMPLATE_PATTERNS):
        return True

    try:
        if detect(text) == "en":
            return True
    except Exception:
        return True

    return False

# â”€â”€ _run_with_timeout â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _run_with_timeout(func, timeout_sec: int):
    import concurrent.futures
    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as ex:
        future = ex.submit(func)
        try:
            return future.result(timeout=timeout_sec)
        except concurrent.futures.TimeoutError:
            raise TimeoutError
