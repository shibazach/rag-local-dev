networks:
  ragnet:
    name: ragnet

volumes:
  pgdata:
  ollama_data:

services:
  ragapp:
    build:
      context: .
      dockerfile: .devcontainer/Dockerfile
    container_name: ragapp
    restart: unless-stopped
    ports:
      - "8501:8501"
      - "8000:8000"
    environment:
      DB_HOST: ragdb
      DB_PORT: "5432"
      DB_NAME: rag
      DB_USER: raguser
      DB_PASSWORD: ragpass
      OLLAMA_BASE: http://ollama:11434
      PYTHONPATH: /workspace
      USE_GPU: "1"  # GPU利用フラグを明示（config.py対応）
      NVIDIA_VISIBLE_DEVICES: all
    depends_on:
      - ragdb
      - ollama
    networks:
      - ragnet
    # command: bash
    command: ["python3", "run_app.py", "fastapi"]
    stdin_open: true
    tty: true
    volumes:
      # ホストのプロジェクトルートを /workspace にマウント
      - ./:/workspace:cached

    # 🔽🔽🔽 GPU 割当追加 🔽🔽🔽
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    devices:
      - "/dev/nvidia0:/dev/nvidia0"
      - "/dev/nvidiactl:/dev/nvidiactl"
      - "/dev/nvidia-uvm:/dev/nvidia-uvm"
      - "/dev/nvidia-uvm-tools:/dev/nvidia-uvm-tools"
    gpus: all

  # PostgreSQL + pgvector
  ragdb:
    image: ankane/pgvector:latest
    container_name: ragdb
    restart: unless-stopped
    environment:
      POSTGRES_DB: rag
      POSTGRES_USER: raguser
      POSTGRES_PASSWORD: ragpass
    volumes:
      - pgdata:/var/lib/postgresql/data
      #- ./.devcontainer/init_pgvector.sql:/docker-entrypoint-initdb.d/init_pgvector.sql:ro
      - ./.devcontainer:/docker-entrypoint-initdb.d:ro
    networks:
      - ragnet
    ports:
      - "5432:5432"

  # Ollama (GPU-enabled) 
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - ragnet
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      NVIDIA_VISIBLE_DEVICES: all
    # ── デバイスマッピング追加 ──
    devices:
      - "/dev/nvidia0:/dev/nvidia0"
      - "/dev/nvidiactl:/dev/nvidiactl"
      - "/dev/nvidia-uvm:/dev/nvidia-uvm"
      - "/dev/nvidia-uvm-tools:/dev/nvidia-uvm-tools"
    gpus: all
    entrypoint: >
      sh -c "ollama serve & sleep 5 && ollama pull gemma:7b && ollama pull nomic-embed-text && wait"
