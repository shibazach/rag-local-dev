networks:
  ragnet:
    name: ragnet

volumes:
  pgdata:
  ollama_data:

services:
  # Streamlit UI + RAGアプリ
  ragapp:
    build:
      context: .
      dockerfile: .devcontainer/Dockerfile
    container_name: ragapp
    restart: unless-stopped
    ports:
      - "8501:8501"
    environment:
      DB_HOST: ragdb
      DB_PORT: "5432"
      DB_NAME: rag
      DB_USER: raguser
      DB_PASSWORD: ragpass
      OLLAMA_URL: http://ollama:11434
      PYTHONPATH: /workspace
    depends_on:
      - ragdb
      - ollama
    networks:
      - ragnet
    working_dir: /workspace
    command: bash
    stdin_open: true
    tty: true
    volumes:
<<<<<<< HEAD
=======
      # ホストのプロジェクトルートを /workspace にマウント
>>>>>>> bbab7da (更新)
      - ./:/workspace:cached

    # PostgreSQL + pgvector
  ragdb:
    image: ankane/pgvector:latest
    container_name: ragdb
    restart: unless-stopped
    environment:
      POSTGRES_DB: rag
      POSTGRES_USER: ragdb
      POSTGRES_PASSWORD: ragpass
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./.devcontainer/init_pgvector.sql:/docker-entrypoint-initdb.d/init_pgvector.sql:ro
    networks:
      - ragnet


  # Ollama (GPU-enabled) 
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - ragnet
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      NVIDIA_VISIBLE_DEVICES: all
    # ── デバイスマッピング追加 ──
    devices:
      - "/dev/nvidia0:/dev/nvidia0"
      - "/dev/nvidiactl:/dev/nvidiactl"
      - "/dev/nvidia-uvm:/dev/nvidia-uvm"
      - "/dev/nvidia-uvm-tools:/dev/nvidia-uvm-tools"
    gpus: all
    entrypoint: >
      sh -c "ollama serve & sleep 5 && ollama pull gemma:7b && ollama pull nomic-embed-text && wait"

