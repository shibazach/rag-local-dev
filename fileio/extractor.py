# fileio/extractor.py
import os, json, csv, subprocess, tempfile
from io import BytesIO
from typing import List

import docx
import fitz  # PyMuPDF
import numpy as np
import pytesseract
from PIL import Image

from src import bootstrap
from ocr import (correct_orientation, detect_rotation_angle)

# PDFã‚’ç”»åƒã«å¤‰æ›ï¼ˆãƒšãƒ¼ã‚¸ã”ã¨ï¼‰
def pdf_page_to_image(pdf_path, page_number, dpi=300) -> Image.Image:
    doc = fitz.open(pdf_path)
    page = doc.load_page(page_number)
    zoom = dpi / 72
    mat = fitz.Matrix(zoom, zoom)
    pix = page.get_pixmap(matrix=mat)
    img_data = pix.tobytes("png")
    return Image.open(BytesIO(img_data))

# PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆï¼ˆPyMuPDF + OCR ä¸¡æ–¹ã€OCRã¯å‘ãè£œæ­£ã¤ãï¼‰
def extract_text_from_pdf(pdf_path: str) -> List[str]:
    doc = fitz.open(pdf_path)
    text_list = []

    for page_number in range(len(doc)):
        page = doc.load_page(page_number)

        # PyMuPDFæŠ½å‡ºï¼ˆãƒ†ã‚­ã‚¹ãƒˆå±¤ï¼‰
        pdf_text = page.get_text().strip()

        # OCRæŠ½å‡ºï¼ˆç”»åƒå±¤ + å‘ãè£œæ­£ï¼‰
        image = pdf_page_to_image(pdf_path, page_number)
        angle = detect_rotation_angle(image)
        rotated = correct_orientation(image, angle)
        ocr_text = pytesseract.image_to_string(rotated, lang="jpn+eng").strip()

        # çµåˆã—ã¦1ãƒšãƒ¼ã‚¸åˆ†ã¨ã—ã¦æ ¼ç´
        merged = f"ã€PDFæŠ½å‡ºã€‘\n{pdf_text}\n\nã€OCRæŠ½å‡ºã€‘\n{ocr_text}"
        text_list.append(merged)

    return text_list

# Wordãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ§‹é€ ã¨OCRã‚’çµ±åˆã—ã¦æŠ½å‡º
def extract_text_from_docx_combined(docx_path: str) -> List[str]:
    structured_text = []

    # ğŸ”¹ è¡¨ã‚„æ®µè½ãªã©ã€è«–ç†æ§‹é€ ãƒ™ãƒ¼ã‚¹ã§æŠ½å‡º
    doc = docx.Document(docx_path)
    structured_text.extend([p.text for p in doc.paragraphs if p.text])

    for table in doc.tables:
        for row in table.rows:
            row_text = [cell.text.strip().replace("\n", " ") for cell in row.cells if cell.text.strip()]
            if row_text:
                structured_text.append(" | ".join(row_text))

    # ğŸ”¹ OCRãƒ™ãƒ¼ã‚¹ï¼ˆLibreOfficeçµŒç”±ã§PDFåŒ– â†’ extract_text_from_pdf ã‚’æµç”¨ï¼‰
    with tempfile.TemporaryDirectory() as tmpdir:
        try:
            subprocess.run([
                "libreoffice", "--headless", "--convert-to", "pdf",
                "--outdir", tmpdir, docx_path
            ], check=True)
        except subprocess.CalledProcessError:
            raise RuntimeError("LibreOfficeã«ã‚ˆã‚‹PDFå¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ")

        basename = os.path.splitext(os.path.basename(docx_path))[0]
        pdf_path = os.path.join(tmpdir, f"{basename}.pdf")
        if os.path.exists(pdf_path):
            ocr_text = extract_text_from_pdf(pdf_path)
        else:
            raise FileNotFoundError(f"PDFå¤‰æ›å¾Œãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pdf_path}")

    # ğŸ”¹ çµ±åˆï¼šã‚¿ã‚°ã‚’ä»˜ã‘ã¦ LLM æ•´å½¢ã«æ¸¡ã™
    return [
        "ã€æ§‹é€ æŠ½å‡ºã€‘\n" + "\n".join(structured_text),
        "ã€OCRæŠ½å‡ºã€‘\n" + "\n".join(ocr_text)
    ]

# TXT
def extract_text_from_txt(txt_path: str) -> List[str]:
    with open(txt_path, encoding="utf-8") as f:
        return [line.strip() for line in f if line.strip()]

# CSVï¼ˆtextã‚«ãƒ©ãƒ ãŒãªã‘ã‚Œã°ãƒ­ã‚°ã«è¨˜éŒ²ã—ã¦ã‚¹ã‚­ãƒƒãƒ—ï¼‰
def extract_text_from_csv(csv_path: str) -> List[str]:
    results = []
    try:
        with open(csv_path, encoding="utf-8") as f:
            reader = csv.DictReader(f)
            if "text" not in reader.fieldnames:
                raise ValueError("CSVã«'text'ã‚«ãƒ©ãƒ ãŒå¿…è¦ã§ã™")
            for row in reader:
                if row.get("text"):
                    results.append(row["text"].strip())
        return results
    except Exception as e:
        os.makedirs("logs", exist_ok=True)
        log_path = os.path.join("logs", "invalid_csv_log.txt")
        from datetime import datetime
        now = datetime.utcnow().isoformat() + "Z"
        with open(log_path, "a", encoding="utf-8") as logf:
            logf.write(f"{now}: Skipped {csv_path} - {e}\n")
        return []

# EMLï¼ˆãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã®ã¿ã‚’å¯¾è±¡ã€å¼•ç”¨é™¤å»ï¼‰
def extract_text_from_eml(filepath: str) -> List[str]:
    from email import policy
    from email.parser import BytesParser

    with open(filepath, "rb") as f:
        msg = BytesParser(policy=policy.default).parse(f)

    text_blocks = []
    for part in msg.walk():
        if part.get_content_type() == "text/plain":
            content = part.get_content()
            lines = content.splitlines()
            # REM: å¼•ç”¨è¡Œï¼ˆ>>ã§å§‹ã¾ã‚‹è¡Œï¼‰ã¯é™¤å»
            lines = [line for line in lines if not line.strip().startswith(">>")]
            filtered = "\n".join(lines).strip()
            if filtered:
                text_blocks.append(filtered)
    return text_blocks

# JSON
def extract_text_from_json(json_path: str) -> List[str]:
    with open(json_path, encoding="utf-8") as f:
        data = json.load(f)
        if not isinstance(data, list):
            raise ValueError("JSONã¯ãƒªã‚¹ãƒˆå½¢å¼ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        return [item["text"] for item in data if "text" in item]

# æ‹¡å¼µå­ã§æŒ¯ã‚Šåˆ†ã‘
def extract_text_by_extension(filepath: str) -> List[str]:
    ext = os.path.splitext(filepath)[1].lower()
    if ext == ".pdf":
        return extract_text_from_pdf(filepath)
    elif ext == ".docx":
        return extract_text_from_docx_combined(filepath)
    elif ext == ".txt":
        return extract_text_from_txt(filepath)
    elif ext == ".csv":
        return extract_text_from_csv(filepath)
    elif ext == ".json":
        return extract_text_from_json(filepath)
    else:
        raise ValueError(f"æœªå¯¾å¿œã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {ext}")
