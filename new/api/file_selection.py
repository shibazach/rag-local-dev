# new/api/file_selection.py
# ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°APIæ‹¡å¼µ

from typing import Dict, List, Optional
from fastapi import APIRouter, HTTPException, Query, Depends, Body
from fastapi.responses import JSONResponse
from sqlalchemy import text
from sqlalchemy.engine import Connection
from pydantic import BaseModel

from database.connection import get_db_connection
from config import LOGGER

router = APIRouter(prefix="/file-selection", tags=["file-selection"])

class FileSelectionRequest(BaseModel):
    file_ids: List[str]
    processing_options: Dict

class FileStatusSummary(BaseModel):
    status: str
    count: int
    percentage: float

class FileSelectionStats(BaseModel):
    total_files: int
    status_breakdown: List[FileStatusSummary]
    selected_files: int
    estimated_processing_time: float

@router.get("/stats")
async def get_file_selection_stats(
    connection: Connection = Depends(get_db_connection)
) -> JSONResponse:
    """ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠçµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
    try:
        # ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥é›†è¨ˆ
        stats_query = text("""
            SELECT
                COUNT(*) as total_files,
                COUNT(CASE WHEN ft.raw_text IS NOT NULL AND ft.refined_text IS NOT NULL THEN 1 END) as processed,
                COUNT(CASE WHEN ft.raw_text IS NOT NULL AND ft.refined_text IS NULL THEN 1 END) as text_extracted,
                COUNT(CASE WHEN ft.raw_text IS NULL THEN 1 END) as pending_processing
            FROM files_blob fb
            JOIN files_meta fm ON fb.id = fm.blob_id
            LEFT JOIN files_text ft ON fb.id = ft.blob_id
        """)
        
        result = connection.execute(stats_query).fetchone()
        
        total_files = result.total_files
        processed = result.processed
        text_extracted = result.text_extracted
        pending_processing = result.pending_processing
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥çµ±è¨ˆ
        status_breakdown = []
        if total_files > 0:
            status_breakdown = [
                {
                    "status": "processed",
                    "count": processed,
                    "percentage": round((processed / total_files) * 100, 1)
                },
                {
                    "status": "text_extracted", 
                    "count": text_extracted,
                    "percentage": round((text_extracted / total_files) * 100, 1)
                },
                {
                    "status": "pending_processing",
                    "count": pending_processing,
                    "percentage": round((pending_processing / total_files) * 100, 1)
                }
            ]
        
        return JSONResponse({
            "total_files": total_files,
            "status_breakdown": status_breakdown,
            "selected_files": 0,  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§æ›´æ–°
            "estimated_processing_time": 0.0
        })
        
    except Exception as e:
        LOGGER.error(f"ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠçµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=f"çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")

@router.get("/filters")
async def get_available_filters(
    connection: Connection = Depends(get_db_connection)
) -> JSONResponse:
    """åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é¸æŠè‚¢ã‚’å–å¾—"""
    try:
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ä»¶æ•°
        status_query = text("""
            SELECT
                CASE
                    WHEN ft.raw_text IS NOT NULL AND ft.refined_text IS NOT NULL THEN 'processed'
                    WHEN ft.raw_text IS NOT NULL THEN 'text_extracted'
                    ELSE 'pending_processing'
                END as status,
                COUNT(*) as count
            FROM files_blob fb
            JOIN files_meta fm ON fb.id = fm.blob_id
            LEFT JOIN files_text ft ON fb.id = ft.blob_id
            GROUP BY
                CASE
                    WHEN ft.raw_text IS NOT NULL AND ft.refined_text IS NOT NULL THEN 'processed'
                    WHEN ft.raw_text IS NOT NULL THEN 'text_extracted'
                    ELSE 'pending_processing'
                END
            ORDER BY count DESC
        """)
        
        status_result = connection.execute(status_query).fetchall()
        status_filters = [{"value": row.status, "count": row.count} for row in status_result]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­åˆ¥ä»¶æ•°
        extension_query = text("""
            SELECT
                LOWER(SUBSTRING(fm.file_name FROM '\\.([^.]*)$')) as extension,
                COUNT(*) as count
            FROM files_blob fb
            JOIN files_meta fm ON fb.id = fm.blob_id
            WHERE fm.file_name ~ '\\.[^.]+$'
            GROUP BY LOWER(SUBSTRING(fm.file_name FROM '\\.([^.]*)$'))
            ORDER BY count DESC
            LIMIT 10
        """)
        
        extension_result = connection.execute(extension_query).fetchall()
        extension_filters = [{"value": row.extension, "count": row.count} for row in extension_result]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¯„å›²
        size_query = text("""
            SELECT
                MIN(fm.size) as min_size,
                MAX(fm.size) as max_size,
                AVG(fm.size) as avg_size
            FROM files_blob fb
            JOIN files_meta fm ON fb.id = fm.blob_id
        """)
        
        size_result = connection.execute(size_query).fetchone()
        
        return JSONResponse({
            "status_filters": status_filters,
            "extension_filters": extension_filters,
            "size_range": {
                "min": int(size_result.min_size) if size_result.min_size else 0,
                "max": int(size_result.max_size) if size_result.max_size else 0,
                "avg": int(size_result.avg_size) if size_result.avg_size else 0
            }
        })
        
    except Exception as e:
        LOGGER.error(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")

@router.post("/estimate")
async def estimate_processing_time(
    request: FileSelectionRequest,
    connection: Connection = Depends(get_db_connection)
) -> JSONResponse:
    """é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†æ™‚é–“ã‚’æ¨å®š"""
    try:
        if not request.file_ids:
            return JSONResponse({
                "selected_count": 0,
                "estimated_time_seconds": 0,
                "estimated_time_display": "00:00",
                "breakdown": {}
            })
        
        # é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°å–å¾—
        file_query = text("""
            SELECT
                fb.id,
                fm.file_name,
                fm.size,
                fm.page_count,
                CASE
                    WHEN ft.raw_text IS NOT NULL AND ft.refined_text IS NOT NULL THEN 'processed'
                    WHEN ft.raw_text IS NOT NULL THEN 'text_extracted'
                    ELSE 'pending_processing'
                END as status
            FROM files_blob fb
            JOIN files_meta fm ON fb.id = fm.blob_id
            LEFT JOIN files_text ft ON fb.id = ft.blob_id
            WHERE fb.id::text = ANY(:file_ids)
        """)
        
        result = connection.execute(file_query, {"file_ids": request.file_ids}).fetchall()
        
        # å‡¦ç†æ™‚é–“æ¨å®šãƒ­ã‚¸ãƒƒã‚¯
        total_time = 0
        breakdown = {
            "ocr_time": 0,
            "llm_time": 0,
            "embedding_time": 0,
            "overhead_time": 0
        }
        
        for file in result:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒ™ãƒ¼ã‚¹ã®æ¨å®šï¼ˆç§’ï¼‰
            file_size_mb = file.size / (1024 * 1024)
            page_count = file.page_count or 1
            
            # OCRæ™‚é–“æ¨å®šï¼ˆãƒšãƒ¼ã‚¸æ•°ã¨ã‚µã‚¤ã‚ºãƒ™ãƒ¼ã‚¹ï¼‰
            ocr_time = max(2.0, page_count * 0.5 + file_size_mb * 0.1)
            
            # LLMæ•´å½¢æ™‚é–“æ¨å®š
            llm_time = max(1.0, page_count * 0.3)
            
            # ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ™‚é–“æ¨å®š
            embedding_time = max(0.5, page_count * 0.1)
            
            # ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰
            overhead_time = 1.0
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è€ƒæ…®
            if file.status == 'processed':
                # å†å‡¦ç†ã®å ´åˆã¯çŸ­ç¸®
                ocr_time *= 0.3
                llm_time *= 0.5
            elif file.status == 'text_extracted':
                # ãƒ†ã‚­ã‚¹ãƒˆæ¸ˆã¿ãªã‚‰OCRã‚¹ã‚­ãƒƒãƒ—
                ocr_time = 0
            
            file_total = ocr_time + llm_time + embedding_time + overhead_time
            total_time += file_total
            
            breakdown["ocr_time"] += ocr_time
            breakdown["llm_time"] += llm_time
            breakdown["embedding_time"] += embedding_time
            breakdown["overhead_time"] += overhead_time
        
        # ä¸¦åˆ—å‡¦ç†åŠ¹æœã‚’è€ƒæ…®
        if len(result) > 1:
            total_time *= 0.8  # 20%çŸ­ç¸®
        
        # æ™‚é–“è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        minutes = int(total_time // 60)
        seconds = int(total_time % 60)
        time_display = f"{minutes:02d}:{seconds:02d}"
        
        return JSONResponse({
            "selected_count": len(result),
            "estimated_time_seconds": round(total_time, 1),
            "estimated_time_display": time_display,
            "breakdown": {
                "ocr_time": round(breakdown["ocr_time"], 1),
                "llm_time": round(breakdown["llm_time"], 1),
                "embedding_time": round(breakdown["embedding_time"], 1),
                "overhead_time": round(breakdown["overhead_time"], 1)
            }
        })
        
    except Exception as e:
        LOGGER.error(f"å‡¦ç†æ™‚é–“æ¨å®šã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=f"æ¨å®šã‚¨ãƒ©ãƒ¼: {str(e)}")

@router.get("/bulk-actions")
async def get_bulk_actions() -> JSONResponse:
    """ä¸€æ‹¬æ“ä½œã®é¸æŠè‚¢ã‚’å–å¾—"""
    return JSONResponse({
        "actions": [
            {
                "id": "process_all",
                "label": "é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†",
                "description": "OCRâ†’LLMâ†’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã®å®Œå…¨å‡¦ç†",
                "icon": "ğŸš€"
            },
            {
                "id": "ocr_only",
                "label": "OCRã®ã¿å®Ÿè¡Œ",
                "description": "ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã®ã¿å®Ÿè¡Œ",
                "icon": "ğŸ“„"
            },
            {
                "id": "reprocess",
                "label": "å†å‡¦ç†",
                "description": "æ—¢å­˜çµæœã‚’ä¸Šæ›¸ãã—ã¦å†å‡¦ç†",
                "icon": "ğŸ”„"
            },
            {
                "id": "mark_processed",
                "label": "å‡¦ç†æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯",
                "description": "æ‰‹å‹•ã§å‡¦ç†æ¸ˆã¿ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¤‰æ›´",
                "icon": "âœ…"
            }
        ]
    })

@router.post("/validate")
async def validate_file_selection(
    request: FileSelectionRequest,
    connection: Connection = Depends(get_db_connection)
) -> JSONResponse:
    """ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯"""
    try:
        if not request.file_ids:
            return JSONResponse({
                "valid": False,
                "errors": ["ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“"],
                "warnings": []
            })
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        existence_query = text("""
            SELECT fb.id, fm.file_name
            FROM files_blob fb
            JOIN files_meta fm ON fb.id = fm.blob_id
            WHERE fb.id::text = ANY(:file_ids)
        """)
        
        result = connection.execute(existence_query, {"file_ids": request.file_ids}).fetchall()
        found_ids = [str(row.id) for row in result]
        missing_ids = [fid for fid in request.file_ids if fid not in found_ids]
        
        errors = []
        warnings = []
        
        if missing_ids:
            errors.append(f"å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ID: {', '.join(missing_ids[:3])}{'...' if len(missing_ids) > 3 else ''}")
        
        if len(request.file_ids) > 100:
            warnings.append("å¤§é‡ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ: å‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        valid = len(errors) == 0
        
        return JSONResponse({
            "valid": valid,
            "errors": errors,
            "warnings": warnings,
            "found_files": len(found_ids),
            "total_selected": len(request.file_ids)
        })
        
    except Exception as e:
        LOGGER.error(f"ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")