#!/usr/bin/env python3
# new/services/embedding_service.py
# ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚µãƒ¼ãƒ“ã‚¹

import logging
import json
import numpy as np
from typing import List, Dict, Any, Optional
from pathlib import Path

from ..config import LOGGER

class EmbeddingService:
    """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        self.default_model = "sentence-transformers"
        self.models = {
            "sentence-transformers": self._get_sentence_transformers_embedding,
            "ollama": self._get_ollama_embedding
        }
    
    def create_embeddings(self, texts: List[str], model_name: str = None) -> List[List[float]]:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
        try:
            model_name = model_name or self.default_model
            LOGGER.info(f"ğŸ§  ãƒ™ã‚¯ãƒˆãƒ«åŒ–é–‹å§‹: {len(texts)}å€‹ã®ãƒ†ã‚­ã‚¹ãƒˆ, ãƒ¢ãƒ‡ãƒ«={model_name}")
            
            if model_name not in self.models:
                raise ValueError(f"æœªå¯¾å¿œã®ãƒ¢ãƒ‡ãƒ«: {model_name}")
            
            embeddings = []
            for i, text in enumerate(texts):
                try:
                    embedding = self.models[model_name](text)
                    embeddings.append(embedding)
                    LOGGER.info(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Œäº†: {i+1}/{len(texts)}")
                except Exception as e:
                    LOGGER.error(f"âŒ ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼: ãƒ†ã‚­ã‚¹ãƒˆ{i+1} - {e}")
                    # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¿½åŠ 
                    embeddings.append([0.0] * 768)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¬¡å…ƒæ•°
            
            LOGGER.info(f"ğŸ‰ ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Œäº†: {len(embeddings)}å€‹")
            return embeddings
            
        except Exception as e:
            LOGGER.error(f"ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _get_sentence_transformers_embedding(self, text: str) -> List[float]:
        """sentence-transformersã‚’ä½¿ç”¨ã—ãŸãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
        try:
            from sentence_transformers import SentenceTransformer
            
            # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆåˆå›ã®ã¿ï¼‰
            if not hasattr(self, '_sentence_model'):
                self._sentence_model = SentenceTransformer('intfloat/e5-large-v2')
            
            # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
            if not text.strip():
                return [0.0] * 1024  # ç©ºãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆã¯ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«
            
            # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            embedding = self._sentence_model.encode(text)
            return embedding.tolist()
            
        except ImportError:
            LOGGER.error("sentence-transformersãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return [0.0] * 1024
        except Exception as e:
            LOGGER.error(f"sentence-transformersã‚¨ãƒ©ãƒ¼: {e}")
            return [0.0] * 1024
    
    def _get_ollama_embedding(self, text: str) -> List[float]:
        """Ollamaã‚’ä½¿ç”¨ã—ãŸãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
        try:
            from langchain_community.embeddings import OllamaEmbeddings
            
            # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆåˆå›ã®ã¿ï¼‰
            if not hasattr(self, '_ollama_model'):
                self._ollama_model = OllamaEmbeddings(model="nomic-embed-text")
            
            # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            embedding = self._ollama_model.embed_query(text)
            return embedding
            
        except ImportError:
            LOGGER.error("langchain_communityãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return [0.0] * 768
        except Exception as e:
            LOGGER.error(f"Ollamaã‚¨ãƒ©ãƒ¼: {e}")
            return [0.0] * 768
    
    def calculate_similarity(self, embedding1: List[float], embedding2: List[float]) -> float:
        """ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
        try:
            vec1 = np.array(embedding1)
            vec2 = np.array(embedding2)
            
            # æ­£è¦åŒ–
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
            similarity = np.dot(vec1, vec2) / (norm1 * norm2)
            return float(similarity)
            
        except Exception as e:
            LOGGER.error(f"é¡ä¼¼åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def find_similar_chunks(self, query_embedding: List[float], chunk_embeddings: List[List[float]], top_k: int = 5) -> List[Dict[str, Any]]:
        """é¡ä¼¼ãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œç´¢"""
        try:
            similarities = []
            
            for i, chunk_embedding in enumerate(chunk_embeddings):
                similarity = self.calculate_similarity(query_embedding, chunk_embedding)
                similarities.append({
                    "index": i,
                    "similarity": similarity
                })
            
            # é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆ
            similarities.sort(key=lambda x: x["similarity"], reverse=True)
            
            # top_kã‚’è¿”ã™
            return similarities[:top_k]
            
        except Exception as e:
            LOGGER.error(f"é¡ä¼¼ãƒãƒ£ãƒ³ã‚¯æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def batch_create_embeddings(self, chunks: List[Dict[str, Any]], model_name: str = None) -> List[Dict[str, Any]]:
        """ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆã‚’ä¸€æ‹¬ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
        try:
            LOGGER.info(f"ğŸ§  ä¸€æ‹¬ãƒ™ã‚¯ãƒˆãƒ«åŒ–é–‹å§‹: {len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯")
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
            texts = [chunk["text"] for chunk in chunks]
            
            # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            embeddings = self.create_embeddings(texts, model_name)
            
            # çµæœã‚’æ§‹ç¯‰
            results = []
            for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
                result = {
                    **chunk,
                    "embedding_vector": json.dumps(embedding),
                    "embedding_model": model_name or self.default_model,
                    "embedding_size": len(embedding)
                }
                results.append(result)
            
            LOGGER.info(f"ğŸ‰ ä¸€æ‹¬ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Œäº†: {len(results)}å€‹")
            return results
            
        except Exception as e:
            LOGGER.error(f"ä¸€æ‹¬ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise 