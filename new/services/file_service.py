#!/usr/bin/env python3
# new/services/file_service.py
# ãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒ¼ãƒ“ã‚¹

import logging
import shutil
from typing import List, Dict, Any, Optional
from pathlib import Path
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_

from ..models import File as FileModel, FileText as FileTextModel
from ..config import LOGGER, INPUT_DIR
from ..utils.file_converter import FileConverter

class FileService:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        pass
    
    def get_files(self, db: Session) -> List[Dict[str, Any]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        try:
            files = db.query(FileModel).order_by(FileModel.created_at.desc()).all()
            
            return [
                {
                    "id": str(file.id),
                    "filename": file.file_name,
                    "file_path": file.file_path,
                    "file_size": file.file_size,
                    "file_type": file.file_type,
                    "status": file.status,
                    "processing_stage": file.processing_stage,
                    "user_id": file.user_id,
                    "created_at": file.created_at.isoformat() if file.created_at else None,
                    "updated_at": file.updated_at.isoformat() if file.updated_at else None,
                    "note": file.note,
                    "file_metadata": file.file_metadata
                }
                for file in files
            ]
        except Exception as e:
            LOGGER.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def get_file(self, db: Session, file_id: str) -> Optional[Dict[str, Any]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°ã‚’å–å¾—"""
        try:
            file = db.query(FileModel).filter(FileModel.id == file_id).first()
            if not file:
                return None
            
            return {
                "id": str(file.id),
                "filename": file.file_name,
                "file_path": file.file_path,
                "file_size": file.file_size,
                "file_type": file.file_type,
                "status": file.status,
                "processing_stage": file.processing_stage,
                "user_id": file.user_id,
                "created_at": file.created_at.isoformat() if file.created_at else None,
                "updated_at": file.updated_at.isoformat() if file.updated_at else None,
                "note": file.note,
                "file_metadata": file.file_metadata
            }
        except Exception as e:
            LOGGER.error(f"ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_file_by_path(self, db: Session, file_path: str) -> Optional[Dict[str, Any]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
        try:
            file = db.query(FileModel).filter(FileModel.file_path == file_path).first()
            if not file:
                return None
            
            return {
                "id": str(file.id),
                "filename": file.file_name,
                "file_path": file.file_path,
                "file_size": file.file_size,
                "file_type": file.file_type,
                "status": file.status,
                "processing_stage": file.processing_stage,
                "user_id": file.user_id,
                "created_at": file.created_at.isoformat() if file.created_at else None,
                "updated_at": file.updated_at.isoformat() if file.updated_at else None,
                "note": file.note,
                "file_metadata": file.file_metadata
            }
        except Exception as e:
            LOGGER.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def save_file(self, db: Session, file_data: Dict[str, Any]) -> FileModel:
        """ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’ä¿å­˜ï¼ˆå®Œå…¨ç‰ˆï¼šPDFå¤‰æ›â†’ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºâ†’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰"""
        try:
            LOGGER.info("=" * 50)
            LOGGER.info("ğŸš€ FileService.save_file å®Œå…¨ç‰ˆé–‹å§‹")
            LOGGER.info(f"ğŸ“‹ å—ä¿¡ãƒ‡ãƒ¼ã‚¿: {file_data}")
            
            # å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            original_path = Path(file_data["file_path"])
            LOGGER.info(f"ğŸ“ å…ƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {original_path}")
            LOGGER.info(f"ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª: {original_path.exists()}")
            
            # ã‚¹ãƒ†ãƒƒãƒ—1: åŸºæœ¬çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            LOGGER.info("ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’DBã«ä¿å­˜")
            file = FileModel(**file_data)
            db.add(file)
            db.commit()
            db.refresh(file)
            LOGGER.info(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: ID={file.id}")
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼åˆ¤å®šã¨å‡¦ç†
            LOGGER.info("ğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼åˆ¤å®šã¨å‡¦ç†é–‹å§‹")
            file_ext = original_path.suffix.lower()
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯PDFå¤‰æ›ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if file_ext in ['.txt', '.json', '.csv', '.md']:
                LOGGER.info(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {original_path.name} - PDFå¤‰æ›ã‚¹ã‚­ãƒƒãƒ—")
                pdf_path = original_path
            else:
                # ãã®ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯PDFå¤‰æ›ã‚’è©¦è¡Œ
                LOGGER.info(f"ğŸ“„ éãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {original_path.name} - PDFå¤‰æ›è©¦è¡Œ")
                pdf_path = original_path.parent / f"{original_path.stem}_converted.pdf"
                
                if FileConverter.is_supported_format(original_path.name):
                    if FileConverter.convert_to_pdf(original_path, pdf_path):
                        LOGGER.info(f"âœ… PDFå¤‰æ›æˆåŠŸ: {pdf_path}")
                        # PDFãƒ‘ã‚¹ã‚’æ›´æ–°
                        file.file_path = str(pdf_path)
                        file.file_type = "PDF"
                        db.commit()
                    else:
                        LOGGER.warning("âš ï¸ PDFå¤‰æ›å¤±æ•—ã€å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨")
                        pdf_path = original_path
                else:
                    LOGGER.warning(f"âš ï¸ æœªå¯¾å¿œå½¢å¼: {original_path.name}")
                    pdf_path = original_path
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆå³åº§å®Ÿè¡Œï¼‰
            LOGGER.info("ğŸ“– ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºé–‹å§‹ï¼ˆå³åº§å®Ÿè¡Œï¼‰")
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯å³åº§ã«ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
            if file_ext in ['.txt', '.json', '.csv', '.md']:
                LOGGER.info(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å³åº§å‡¦ç†: {original_path.name}")
                text_content = FileConverter._extract_text_direct(original_path)
                
                if text_content:
                    LOGGER.info(f"âœ… ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºæˆåŠŸ: {len(text_content)}æ–‡å­—")
                    # ãƒ†ã‚­ã‚¹ãƒˆã‚’DBã«ä¿å­˜
                    self.save_file_text(db, file.id, text_content)
                    file.status = "text_extracted"
                else:
                    LOGGER.warning("âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå¤±æ•—")
                    file.status = "text_extraction_failed"
                
                db.commit()
                LOGGER.info(f"âœ… ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜å®Œäº†: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹={file.status}")
            else:
                # ãã®ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å¾Œå‡¦ç†å¯¾è±¡ã¨ã—ã¦ãƒãƒ¼ã‚¯
                LOGGER.info(f"ğŸ“„ å¾Œå‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {original_path.name}")
                file.status = "pending_processing"
                db.commit()
                LOGGER.info(f"âœ… å¾Œå‡¦ç†å¯¾è±¡ã¨ã—ã¦ãƒãƒ¼ã‚¯: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹={file.status}")
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆå°†æ¥çš„ã«å®Ÿè£…ï¼‰
            LOGGER.info("ğŸ§  ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆå°†æ¥å®Ÿè£…äºˆå®šï¼‰")
            # TODO: ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            
            # å…ƒãƒ•ã‚¡ã‚¤ãƒ«ãŒPDFã§ãªã„å ´åˆã¯å‰Šé™¤
            if original_path != pdf_path and original_path.exists():
                try:
                    original_path.unlink()
                    LOGGER.info(f"ğŸ—‘ï¸ å…ƒãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {original_path}")
                except Exception as e:
                    LOGGER.warning(f"âš ï¸ å…ƒãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¤±æ•—: {e}")
            
            LOGGER.info("=" * 50)
            LOGGER.info(f"ğŸ‰ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Œäº†: ID={file.id}, ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹={file.status}")
            LOGGER.info("=" * 50)
            return file
                
        except Exception as e:
            LOGGER.error("=" * 50)
            LOGGER.error("ğŸ’¥ FileService.save_file ã‚¨ãƒ©ãƒ¼")
            LOGGER.error(f"âŒ ã‚¨ãƒ©ãƒ¼å†…å®¹: {e}")
            LOGGER.error(f"ğŸ“‹ ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
            import traceback
            LOGGER.error(f"ğŸ“‹ è©³ç´°ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹:")
            LOGGER.error(traceback.format_exc())
            LOGGER.error("=" * 50)
            
            db.rollback()
            LOGGER.error("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†")
            raise
    
    def save_file_text(self, db: Session, file_id: str, text_content: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜"""
        try:
            # æ—¢å­˜ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰Šé™¤
            db.query(FileTextModel).filter(FileTextModel.file_id == file_id).delete()
            
            # æ–°ã—ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
            file_text = FileTextModel(
                file_id=file_id,
                raw_text=text_content,
                refined_text=text_content,  # ç°¡æ˜“çš„ã«åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
                quality_score=1.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            )
            
            db.add(file_text)
            db.commit()
            
            LOGGER.info(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜å®Œäº†: ãƒ•ã‚¡ã‚¤ãƒ«ID={file_id}")
            return True
            
        except Exception as e:
            LOGGER.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            db.rollback()
            return False
    
    def get_file_text(self, db: Session, file_id: str) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
        try:
            file_text = db.query(FileTextModel).filter(FileTextModel.file_id == file_id).first()
            if not file_text:
                return None
            
            return file_text.raw_text
            
        except Exception as e:
            LOGGER.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_file_preview(self, db: Session, file_id: str) -> Optional[Dict[str, Any]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—"""
        try:
            file = db.query(FileModel).filter(FileModel.id == file_id).first()
            if not file:
                return None
            
            file_path = Path(file.file_path)
            if not file_path.exists():
                return None
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
            preview = {
                "id": str(file.id),
                "filename": file.file_name,
                "file_size": file.file_size,
                "file_type": file.file_type,
                "status": file.status,
                "processing_stage": file.processing_stage,
                "created_at": file.created_at.isoformat() if file.created_at else None
            }
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            file_text = db.query(FileTextModel).filter(FileTextModel.file_id == file_id).first()
            if file_text:
                preview["text_preview"] = file_text.raw_text[:500] + "..." if len(file_text.raw_text) > 500 else file_text.raw_text
                preview["text_length"] = len(file_text.raw_text)
                preview["quality_score"] = file_text.quality_score
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæƒ…å ±
            try:
                stat = file_path.stat()
                preview["actual_size"] = stat.st_size
                preview["modified_time"] = stat.st_mtime
            except Exception as e:
                LOGGER.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            
            return preview
            
        except Exception as e:
            LOGGER.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def upload_folder(self, db: Session, folder_path: str, include_subfolders: bool, user_id: int) -> List[Dict[str, Any]]:
        """ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        try:
            folder_dir = INPUT_DIR / folder_path
            if not folder_dir.exists():
                raise ValueError("æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            results = []
            # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å‡¦ç†ã®é¸æŠ
            if include_subfolders:
                file_paths = folder_dir.rglob("*")
            else:
                file_paths = folder_dir.iterdir()
            
            for file_path in file_paths:
                if file_path.is_file():
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
                    file_size = file_path.stat().st_size
                    if file_size > 50 * 1024 * 1024:
                        results.append({
                            "filename": file_path.name,
                            "success": False,
                            "error": "ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ50MBã‚’è¶…ãˆã¦ã„ã¾ã™"
                        })
                        continue
                    
                    # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ï¼‰
                    existing_file = self.get_file_by_path(db, str(file_path))
                    if existing_file:
                        results.append({
                            "filename": file_path.name,
                            "success": False,
                            "error": "ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ—¢ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã§ã™"
                        })
                        continue
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¨˜éŒ²
                    file_data = {
                        "file_name": file_path.name,
                        "file_path": str(file_path),
                        "file_size": file_size,
                        "status": "uploaded",
                        "user_id": user_id
                    }
                    
                    saved_file = self.save_file(db, file_data)
                    
                    results.append({
                        "filename": file_path.name,
                        "success": True,
                        "file_id": str(saved_file.id),
                        "status": saved_file.status
                    })
            
            return results
            
        except Exception as e:
            LOGGER.error(f"ãƒ•ã‚©ãƒ«ãƒ€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def get_pending_files(self, db: Session) -> List[Dict[str, Any]]:
        """å¾Œå‡¦ç†å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        try:
            files = db.query(FileModel).filter(
                FileModel.status == "pending_processing"
            ).all()
            
            return [
                {
                    "id": str(file.id),
                    "filename": file.file_name,
                    "file_path": file.file_path,
                    "file_size": file.file_size,
                    "status": file.status,
                    "user_id": file.user_id,
                    "created_at": file.created_at.isoformat() if file.created_at else None
                }
                for file in files
            ]
        except Exception as e:
            LOGGER.error(f"å¾Œå‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def process_pending_file(self, db: Session, file_id: str) -> bool:
        """å¾Œå‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†"""
        try:
            file = db.query(FileModel).filter(FileModel.id == file_id).first()
            if not file:
                LOGGER.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: ID={file_id}")
                return False
            
            file_path = Path(file.file_path)
            LOGGER.info(f"ğŸ”„ å¾Œå‡¦ç†é–‹å§‹: {file.file_name}")
            
            # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
            text_content = FileConverter.extract_text_from_file(file_path)
            
            if text_content:
                LOGGER.info(f"âœ… ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºæˆåŠŸ: {len(text_content)}æ–‡å­—")
                # ãƒ†ã‚­ã‚¹ãƒˆã‚’DBã«ä¿å­˜
                self.save_file_text(db, file.id, text_content)
                file.status = "text_extracted"
                db.commit()
                LOGGER.info(f"âœ… å¾Œå‡¦ç†å®Œäº†: ID={file.id}")
                return True
            else:
                LOGGER.warning(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå¤±æ•—: ID={file.id}")
                file.status = "text_extraction_failed"
                db.commit()
                return False
                
        except Exception as e:
            LOGGER.error(f"å¾Œå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def process_all_pending_files(self, db: Session) -> Dict[str, int]:
        """å…¨å¾Œå‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†"""
        try:
            pending_files = self.get_pending_files(db)
            LOGGER.info(f"ğŸ”„ å¾Œå‡¦ç†é–‹å§‹: {len(pending_files)}ä»¶")
            
            success_count = 0
            error_count = 0
            
            for file_data in pending_files:
                if self.process_pending_file(db, file_data["id"]):
                    success_count += 1
                else:
                    error_count += 1
            
            LOGGER.info(f"âœ… å¾Œå‡¦ç†å®Œäº†: æˆåŠŸ={success_count}ä»¶, å¤±æ•—={error_count}ä»¶")
            return {
                "success": success_count,
                "error": error_count,
                "total": len(pending_files)
            }
            
        except Exception as e:
            LOGGER.error(f"å¾Œå‡¦ç†ä¸€æ‹¬å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def delete_file(self, db: Session, file_id: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
        try:
            file = db.query(FileModel).filter(FileModel.id == file_id).first()
            if not file:
                return False
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            file_path = Path(file.file_path)
            if file_path.exists():
                file_path.unlink()
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å‰Šé™¤
            db.delete(file)
            db.commit()
            
            LOGGER.info(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å®Œäº†: ID={file_id}")
            return True
            
        except Exception as e:
            LOGGER.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
            db.rollback()
            return False 