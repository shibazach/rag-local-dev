# new/services/processing/pipeline.py
# å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆç®¡ç†

import asyncio
import logging
from typing import Dict, List, AsyncGenerator, Optional

from .processor import FileProcessor
from new.config import LOGGER

class ProcessingPipeline:
    """ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆç®¡ç†"""
    
    def __init__(self):
        self.processor = FileProcessor()
        self.logger = logging.getLogger(__name__)
        self.current_job = None
        self.abort_flag = None
    
    async def process_files(
        self,
        files: List[Dict],
        settings: Dict,
        progress_callback: Optional[callable] = None
    ) -> AsyncGenerator[Dict, None]:
        """
        è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é †æ¬¡å‡¦ç†
        
        Args:
            files: ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ãƒªã‚¹ãƒˆ
            settings: å‡¦ç†è¨­å®š
            progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
            
        Yields:
            å‡¦ç†é€²æ—ã‚¤ãƒ™ãƒ³ãƒˆ
        """
        total_files = len(files)
        self.abort_flag = {'flag': False}
        
        try:
            # é–‹å§‹ã‚¤ãƒ™ãƒ³ãƒˆ
            start_event = {
                'type': 'start',
                'data': {
                    'total_files': total_files,
                    'settings': settings
                }
            }
            self.logger.debug(f"[DEBUG-PIPELINE] é–‹å§‹ã‚¤ãƒ™ãƒ³ãƒˆç”Ÿæˆ: {total_files}ä»¶")
            yield start_event
            
            for idx, file_info in enumerate(files, 1):
                # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒã‚§ãƒƒã‚¯
                if self.abort_flag['flag']:
                    yield {
                        'type': 'cancelled',
                        'message': 'å‡¦ç†ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ'
                    }
                    break
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹
                file_id = str(file_info['file_id'])
                file_name = file_info['file_name']
                file_path = file_info['file_path']
                
                yield {
                    'type': 'file_start',
                    'data': {
                        'file_name': file_name,
                        'file_id': file_id,  # file_idã‚’è¿½åŠ 
                        'file_index': idx,
                        'total_files': total_files,
                        'progress': round((idx - 1) / total_files * 100, 1)
                    }
                }
                
                # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®é€²æ—å‡¦ç†ã¯å¾Œã§å®Ÿè£…
                # ç¾åœ¨ã¯ç›´æ¥å‡¦ç†å®Ÿè¡Œ
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Ÿè¡Œ + è©³ç´°æ‰‹é †ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡ï¼ˆé‡è¤‡ã‚¤ãƒ™ãƒ³ãƒˆå‰Šé™¤ï¼‰
                
                # è©³ç´°æ‰‹é †ã‚’å—ä¿¡ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½œæˆ
                progress_events = []
                
                def progress_callback(event_data):
                    """processor ã‹ã‚‰ã®è©³ç´°æ‰‹é †ã‚’åé›†"""
                    progress_events.append({
                        'type': 'file_progress',
                        'data': {
                            'file_name': file_name,
                            'file_index': idx,
                            'step': event_data.get('step'),
                            'detail': event_data.get('detail'),
                            'progress': event_data.get('progress'),
                            'ocr_text': event_data.get('ocr_text'),  # OCRãƒ†ã‚­ã‚¹ãƒˆ
                            'llm_prompt': event_data.get('llm_prompt'),  # LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                            'llm_result': event_data.get('llm_result')   # LLMçµæœ
                        }
                    })
                
                result = await self.processor.process_file(
                    file_id=file_id,
                    file_name=file_name,
                    file_path=file_path,
                    settings=settings,
                    progress_callback=progress_callback,  # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯æœ‰åŠ¹åŒ–
                    abort_flag=self.abort_flag
                )
                
                # åé›†ã—ãŸè©³ç´°æ‰‹é †ã‚¤ãƒ™ãƒ³ãƒˆã‚’é€ä¿¡
                for progress_event in progress_events:
                    yield progress_event
                
                # å„æ®µéšå®Œäº†ã‚¤ãƒ™ãƒ³ãƒˆã‚’é€ä¿¡
                if result.get('success'):
                    yield {
                        'type': 'file_progress',
                        'data': {
                            'file_name': file_name,
                            'file_index': idx,
                            'step': 'ğŸ“Š OCRå‡¦ç†å®Œäº†',
                            'detail': f"{result.get('text_length', 0)}æ–‡å­—æŠ½å‡º",
                            'progress': 30
                        }
                    }
                    
                    yield {
                        'type': 'file_progress',
                        'data': {
                            'file_name': file_name,
                            'file_index': idx,
                            'step': 'ğŸ¤– LLMç²¾ç·»åŒ–å®Œäº†',
                            'detail': 'ãƒ†ã‚­ã‚¹ãƒˆå“è³ªå‘ä¸Šå‡¦ç†',
                            'progress': 60
                        }
                    }
                    
                    yield {
                        'type': 'file_progress',
                        'data': {
                            'file_name': file_name,
                            'file_index': idx,
                            'step': 'ğŸ§® åŸ‹ã‚è¾¼ã¿ç”Ÿæˆå®Œäº†',
                            'detail': 'ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†å®Œäº†',
                            'progress': 80
                        }
                    }
                    
                    yield {
                        'type': 'file_progress',
                        'data': {
                            'file_name': file_name,
                            'file_index': idx,
                            'step': 'ğŸ‰ å‡¦ç†å®Œäº†',
                            'detail': f'å…¨æ®µéšå®Œäº†',
                            'progress': 100
                        }
                    }
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å®Œäº†ã‚¤ãƒ™ãƒ³ãƒˆ
                event_data = {
                    'type': 'file_complete',
                    'data': {
                        'file_name': file_name,
                        'file_index': idx,
                        'total_files': total_files,
                        'progress': round(idx / total_files * 100, 1),
                        'result': result
                    }
                }
                self.logger.debug(f"[DEBUG-PIPELINE] ã‚¤ãƒ™ãƒ³ãƒˆç”Ÿæˆ: {event_data['type']}, ãƒ•ã‚¡ã‚¤ãƒ«: {file_name}")
                yield event_data
                
                # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
                if result['status'] == 'error':
                    self.logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ [{file_name}]: {result['error']}")
                elif result['status'] == 'cancelled':
                    self.logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚­ãƒ£ãƒ³ã‚»ãƒ« [{file_name}]")
                    break
            
            # å…¨ä½“å®Œäº†
            if not self.abort_flag['flag']:
                complete_event = {
                    'type': 'complete',
                    'data': {
                        'total_files': total_files,
                        'message': 'ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ'
                    }
                }
                self.logger.debug(f"[DEBUG-PIPELINE] å®Œäº†ã‚¤ãƒ™ãƒ³ãƒˆç”Ÿæˆ")
                yield complete_event
            
        except Exception as e:
            self.logger.error(f"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            yield {
                'type': 'error',
                'message': f'å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}'
            }
    
    def cancel_processing(self):
        """å‡¦ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
        if self.abort_flag:
            self.abort_flag['flag'] = True
            self.logger.info("å‡¦ç†ã‚­ãƒ£ãƒ³ã‚»ãƒ«è¦æ±‚")
    
    def is_processing(self) -> bool:
        """å‡¦ç†ä¸­ã‹ã©ã†ã‹"""
        return self.current_job is not None