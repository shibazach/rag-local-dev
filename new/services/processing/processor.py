# new/services/processing/processor.py
# ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ—ãƒ­ã‚»ãƒƒã‚µï¼ˆæ–°ç³»ï¼‰

import asyncio
import time
import logging
import unicodedata
from pathlib import Path
from typing import Dict, List, Optional, AsyncGenerator
import uuid

from new.services.ocr.factory import OCREngineFactory
from new.database.connection import get_db_connection
from new.config import LOGGER, DB_ENGINE

class FileProcessor:
    """æ–°ç³»ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ—ãƒ­ã‚»ãƒƒã‚µ"""
    
    def __init__(self):
        self.ocr_factory = OCREngineFactory()
        self.logger = logging.getLogger(__name__)
    
    async def process_file(
        self,
        file_id: str,
        file_name: str,
        file_path: str,
        settings: Dict,
        progress_callback: Optional[callable] = None,
        abort_flag: Optional[Dict] = None,
        save_to_db: bool = True
    ) -> Dict:
        """
        1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹
        
        Args:
            file_id: ãƒ•ã‚¡ã‚¤ãƒ«ID
            file_name: ãƒ•ã‚¡ã‚¤ãƒ«å
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            settings: å‡¦ç†è¨­å®š
            progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
            abort_flag: ä¸­æ–­ãƒ•ãƒ©ã‚°
            
        Returns:
            å‡¦ç†çµæœè¾æ›¸
        """
        start_time = time.perf_counter()
        result = {
            'success': False,
            'file_id': file_id,
            'file_name': file_name,
            'status': 'processing',
            'steps': {},
            'text_length': 0,
            'processing_time': 0,
            'error': None,
            'ocr_result': {},
            'llm_refined_text': '',
            'quality_score': 0.0
        }
        
        try:
            # ä¸­æ–­ãƒã‚§ãƒƒã‚¯
            if abort_flag and abort_flag.get('flag', False):
                result['status'] = 'cancelled'
                return result
            
            # 1. OCRå‡¦ç†
            self.logger.info(f"ğŸ“„ {file_name}: ğŸ” OCRå‡¦ç†é–‹å§‹ - ã‚¨ãƒ³ã‚¸ãƒ³: {settings.get('ocr_engine', 'ocrmypdf')}")
            await self._emit_progress_with_data(progress_callback, {
                'file_name': file_name,
                'step': 'ğŸ” OCRå‡¦ç†é–‹å§‹',
                'detail': f"ã‚¨ãƒ³ã‚¸ãƒ³: {settings.get('ocr_engine', 'ocrmypdf')}",
                'progress': 10
            })
            ocr_result = await self._process_ocr(file_path, settings, abort_flag)
            
            if not ocr_result['success']:
                result['status'] = 'error'
                result['error'] = ocr_result['error']
                self.logger.error(f"ğŸ“„ {file_name}: âŒ OCRå‡¦ç†å¤±æ•— - {ocr_result['error']}")
                await self._emit_progress(progress_callback, file_name, "âŒ OCRå‡¦ç†å¤±æ•—", ocr_result['error'])
                return result
            
            result['steps']['ocr'] = {
                'success': True,
                'processing_time': ocr_result['processing_time'],
                'text_length': len(ocr_result['text'])
            }
            
            raw_text = ocr_result['text']
            result['text_length'] = len(raw_text)
            
            ocr_message = f"{len(raw_text)}æ–‡å­—æŠ½å‡º ({ocr_result['processing_time']:.1f}ç§’)"
            self.logger.info(f"ğŸ“„ {file_name}: ğŸ“Š OCRå‡¦ç†å®Œäº† - {ocr_message}")
            
            # OCRãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€è©³ç´°æƒ…å ±ã‚’é€ä¿¡
            await self._emit_progress_with_data(progress_callback, {
                'file_name': file_name,
                'step': 'ğŸ“Š OCRå‡¦ç†å®Œäº†',
                'detail': ocr_message,
                'progress': 30,
                'ocr_text': raw_text  # OCRãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 
            })
            
            # ä¸­æ–­ãƒã‚§ãƒƒã‚¯
            if abort_flag and abort_flag.get('flag', False):
                result['status'] = 'cancelled'
                return result
            
            # 2. ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–
            await self._emit_progress_with_data(progress_callback, {
                'file_name': file_name,
                'step': 'ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–',
                'detail': f'{len(raw_text)}æ–‡å­—ã®æ­£è¦åŒ–å‡¦ç†',
                'progress': 40
            })
            normalized_text = self._normalize_text(raw_text)
            
            # 3. LLMæ•´å½¢å‡¦ç†ï¼ˆè©³ç´°é€²æ—ä»˜ãï¼‰
            self.logger.info(f"ğŸ“„ {file_name}: ğŸ¤– LLMç²¾ç·»åŒ–é–‹å§‹ - ãƒ†ã‚­ã‚¹ãƒˆå“è³ªå‘ä¸Šå‡¦ç†")
            
            # LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆã¨é€ä¿¡å‰è¡¨ç¤º
            llm_prompt = self._create_llm_prompt(normalized_text, settings)
            await self._emit_progress_with_data(progress_callback, {
                'file_name': file_name,
                'step': 'ğŸ“ LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº†',
                'detail': f'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº† - åŸæ–‡{len(normalized_text)}æ–‡å­—',
                'progress': 35,
                'llm_prompt': llm_prompt,
                'llm_result': None
            })
            
            # LLMå‡¦ç†é–‹å§‹è¡¨ç¤º
            await self._emit_progress_with_data(progress_callback, {
                'file_name': file_name,
                'step': 'ğŸ¤– LLMå‡¦ç†é–‹å§‹',
                'detail': 'å“è³ªå‘ä¸Šå‡¦ç†å®Ÿè¡Œä¸­',
                'progress': 50
            })
            
            # å®Ÿéš›ã®LLMå‡¦ç†å®Ÿè¡Œ
            llm_start_time = time.perf_counter()
            refined_text = await self._process_llm_refinement(normalized_text, settings, abort_flag)
            llm_processing_time = time.perf_counter() - llm_start_time
            
            if not refined_text:
                # LLMå¤±æ•—æ™‚ã¯æ­£è¦åŒ–ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
                refined_text = normalized_text
                self.logger.warning(f"ğŸ“„ {file_name}: âš ï¸ LLMå‡¦ç†å¤±æ•— - æ­£è¦åŒ–ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨")
                await self._emit_progress_with_data(progress_callback, {
                    'file_name': file_name,
                    'step': 'âš ï¸ LLMå‡¦ç†å¤±æ•—',
                    'detail': 'æ­£è¦åŒ–ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨',
                    'progress': 60
                })
            else:
                llm_message = f"{len(refined_text)}æ–‡å­— (å“è³ªå‘ä¸Š) - å‡¦ç†æ™‚é–“: {llm_processing_time:.1f}ç§’"
                self.logger.info(f"ğŸ“„ {file_name}: âœ¨ LLMç²¾ç·»åŒ–å®Œäº† - {llm_message}")
                
                # LLMçµæœã‚’å«ã‚€è©³ç´°æƒ…å ±ã‚’é€ä¿¡
                await self._emit_progress_with_data(progress_callback, {
                    'file_name': file_name,
                    'step': 'âœ¨ LLMç²¾ç·»åŒ–å®Œäº†',
                    'detail': llm_message,
                    'progress': 60,
                    'llm_prompt': llm_prompt,
                    'llm_result': refined_text
                })
            
            result['steps']['llm'] = {
                'success': bool(refined_text),
                'refined_length': len(refined_text) if refined_text else 0
            }
            
            # ä¸­æ–­ãƒã‚§ãƒƒã‚¯
            if abort_flag and abort_flag.get('flag', False):
                result['status'] = 'cancelled'
                return result
            
            # 4. ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†ï¼ˆæ¨¡æ“¬å®Ÿè£…ï¼‰
            models = settings.get('embedding_models', ['intfloat-e5-large-v2'])
            embedding_message = f"ãƒ¢ãƒ‡ãƒ«: {', '.join(models)}"
            self.logger.info(f"ğŸ“„ {file_name}: ğŸ§® åŸ‹ã‚è¾¼ã¿ç”Ÿæˆé–‹å§‹ - {embedding_message}")
            await self._emit_progress_with_data(progress_callback, {
                'file_name': file_name,
                'step': 'ğŸ§® åŸ‹ã‚è¾¼ã¿ç”Ÿæˆé–‹å§‹',
                'detail': embedding_message,
                'progress': 70
            })
            embedding_result = await self._process_embedding(refined_text, settings, abort_flag)
            
            result['steps']['embedding'] = {
                'success': embedding_result['success'],
                'models': embedding_result.get('models', [])
            }
            
            if embedding_result['success']:
                embedding_complete_msg = f"{len(models)}ãƒ¢ãƒ‡ãƒ«å‡¦ç†å®Œäº†"
                self.logger.info(f"ğŸ“„ {file_name}: âœ… åŸ‹ã‚è¾¼ã¿ç”Ÿæˆå®Œäº† - {embedding_complete_msg}")
                await self._emit_progress_with_data(progress_callback, {
                    'file_name': file_name,
                    'step': 'âœ… åŸ‹ã‚è¾¼ã¿ç”Ÿæˆå®Œäº†',
                    'detail': embedding_complete_msg,
                    'progress': 80
                })
            else:
                self.logger.error(f"ğŸ“„ {file_name}: âŒ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆå¤±æ•— - ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼")
                await self._emit_progress_with_data(progress_callback, {
                    'file_name': file_name,
                    'step': 'âŒ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆå¤±æ•—',
                    'detail': 'ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼',
                    'progress': 80
                })
            
            # 5. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
            if save_to_db:
                self.logger.info(f"ğŸ“„ {file_name}: ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ä¸­ - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ãƒ™ã‚¯ãƒˆãƒ«ä¿å­˜")
                await self._emit_progress_with_data(progress_callback, {
                    'file_name': file_name,
                    'step': 'ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ä¸­',
                    'detail': 'ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ãƒ™ã‚¯ãƒˆãƒ«ä¿å­˜',
                    'progress': 90
                })
                await self._save_to_database(file_id, raw_text, refined_text, settings)
                self.logger.info(f"ğŸ“„ {file_name}: ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº† - å…¨ãƒ‡ãƒ¼ã‚¿ä¿å­˜æ¸ˆã¿")
                await self._emit_progress_with_data(progress_callback, {
                    'file_name': file_name,
                    'step': 'ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº†',
                    'detail': 'å…¨ãƒ‡ãƒ¼ã‚¿ä¿å­˜æ¸ˆã¿',
                    'progress': 95
                })
            else:
                result['db_save'] = {'success': True, 'message': 'DBä¿å­˜ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼‰'}
            
            # å®Œäº†
            processing_time = time.perf_counter() - start_time
            result['success'] = True
            result['status'] = 'completed'
            
            # å„æ®µéšã®æ™‚é–“ã‚’è©³ç´°è¡¨ç¤º
            ocr_time = result['steps']['ocr'].get('processing_time', 0)
            llm_time = llm_processing_time if 'llm_processing_time' in locals() else 0
            
            complete_message = f"åˆè¨ˆ {processing_time:.1f}ç§’ (OCR: {ocr_time:.1f}s, LLM: {llm_time:.1f}s)"
            self.logger.info(f"ğŸ“„ {file_name}: ğŸ‰ å‡¦ç†å®Œäº† - {complete_message}")
            await self._emit_progress_with_data(progress_callback, {
                'file_name': file_name,
                'step': 'ğŸ‰ å‡¦ç†å®Œäº†',
                'detail': complete_message,
                'progress': 100,
                'total_processing_time': processing_time,
                'ocr_time': ocr_time,
                'llm_time': llm_time
            })
            result['processing_time'] = time.perf_counter() - start_time
            result['ocr_result'] = {'text': raw_text, 'success': True}
            result['llm_refined_text'] = refined_text
            

            
        except Exception as e:
            self.logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ [{file_name}]: {e}")
            result['status'] = 'error'
            result['error'] = str(e)
            result['processing_time'] = time.perf_counter() - start_time
        
        return result
    
    async def _process_ocr(self, file_path: str, settings: Dict, abort_flag: Optional[Dict]) -> Dict:
        """OCRå‡¦ç†ã‚’å®Ÿè¡Œï¼ˆãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼‰"""
        start_time = time.perf_counter()
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
            if not Path(file_path).exists():
                return {
                    'success': False,
                    'error': f'ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}',
                    'text': '',
                    'processing_time': 0
                }
            
            file_ext = Path(file_path).suffix.lower()
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ç›´æ¥èª­ã¿è¾¼ã¿
            if file_ext in ['.txt', '.csv', '.json']:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        text = f.read()
                    
                    processing_time = time.perf_counter() - start_time
                    
                    return {
                        'success': True,
                        'error': None,
                        'text': text,
                        'processing_time': processing_time
                    }
                except Exception as e:
                    return {
                        'success': False,
                        'error': f'ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}',
                        'text': '',
                        'processing_time': time.perf_counter() - start_time
                    }
            
            # PDF/ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯OCRã‚¨ãƒ³ã‚¸ãƒ³ä½¿ç”¨
            elif file_ext in ['.pdf', '.png', '.jpg', '.jpeg', '.tiff', '.bmp']:
                # OCRã‚¨ãƒ³ã‚¸ãƒ³å–å¾—
                engine_id = settings.get('ocr_engine', 'ocrmypdf')
                self.logger.info(f"OCRã‚¨ãƒ³ã‚¸ãƒ³ {engine_id} ã§å‡¦ç†é–‹å§‹ä¸­...")
                
                # å‡¦ç†ä¸­ã®è©³ç´°é€²æ—è¡¨ç¤º
                processing_start = time.perf_counter()
                
                # OCRå‡¦ç†ä¸­ã®é€²æ—é€šçŸ¥
                await self._emit_progress_with_data(progress_callback, {
                    'file_name': file_name,
                    'step': 'ğŸ“„ OCRå‡¦ç†å®Ÿè¡Œä¸­',
                    'detail': f'ã‚¨ãƒ³ã‚¸ãƒ³: {engine_id} - ãƒšãƒ¼ã‚¸è§£æä¸­...',
                    'progress': 25,
                    'ocr_engine': engine_id,
                    'stage': 'ocr_processing'
                })
                
                # ã‚·ãƒ³ãƒ—ãƒ«é€²æ—ç›£è¦–ï¼ˆ10ç§’æ¯ï¼‰
                async def ocr_progress_monitor():
                    start_time = time.perf_counter()
                    page_estimate = 1
                    total_pages = 8  # æ¨å®šãƒšãƒ¼ã‚¸æ•°ï¼ˆPDFã®å ´åˆï¼‰
                    
                    while True:
                        await asyncio.sleep(10)
                        elapsed = time.perf_counter() - start_time
                        
                        # çµŒéæ™‚é–“ã«å¿œã˜ã¦ãƒšãƒ¼ã‚¸æ•°ã‚’æ¨å®šï¼ˆ15ç§’/ãƒšãƒ¼ã‚¸ã¨ä»®å®šï¼‰
                        page_estimate = min(int(elapsed / 15) + 1, total_pages)
                        
                        await self._emit_progress_with_data(callback, {
                            'file_name': file_name,
                            'step': f'OCRå‡¦ç†ä¸­ - {page_estimate}/{total_pages}ãƒšãƒ¼ã‚¸',
                            'detail': f'({elapsed:.0f}ç§’çµŒé)',
                            'progress': min(25 + (elapsed / 60) * 25, 45),
                            'stage': 'ocr_processing',
                            'elapsed_ocr': elapsed,
                            'simple_status': True  # ã‚·ãƒ³ãƒ—ãƒ«è¡¨ç¤ºãƒ•ãƒ©ã‚°
                        })
                
                # é€²æ—ç›£è¦–ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
                monitor_task = asyncio.create_task(ocr_progress_monitor())
                
                try:
                    ocr_result = self.ocr_factory.process_file(file_path, engine_id=engine_id)
                    processing_time = time.perf_counter() - processing_start
                finally:
                    # ç›£è¦–ã‚¿ã‚¹ã‚¯ã‚’çµ‚äº†
                    monitor_task.cancel()
                    try:
                        await monitor_task
                    except asyncio.CancelledError:
                        pass
                
                self.logger.info(f"OCRå‡¦ç†å®Œäº† - å‡¦ç†æ™‚é–“: {processing_time:.1f}ç§’")
                
                # ä¸­æ–­ãƒã‚§ãƒƒã‚¯
                if abort_flag and abort_flag.get('flag', False):
                    return {
                        'success': False,
                        'error': 'ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ',
                        'text': '',
                        'processing_time': ocr_result.processing_time
                    }
                
                return {
                    'success': ocr_result.success,
                    'error': ocr_result.error,
                    'text': ocr_result.text or '',
                    'processing_time': ocr_result.processing_time
                }
            
            else:
                return {
                    'success': False,
                    'error': f'ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {file_ext}',
                    'text': '',
                    'processing_time': time.perf_counter() - start_time
                }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'OCRå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}',
                'text': '',
                'processing_time': time.perf_counter() - start_time
            }
    
    def _normalize_text(self, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–"""
        if not text:
            return ""
        
        # Unicodeæ­£è¦åŒ–
        normalized = unicodedata.normalize("NFKC", text)
        
        # æ”¹è¡Œãƒ»ç©ºç™½ã®æ­£è¦åŒ–
        lines = []
        for line in normalized.split('\n'):
            line = line.strip()
            if line:
                lines.append(line)
        
        return '\n'.join(lines)
    
    async def _process_llm_refinement(self, text: str, settings: Dict, abort_flag: Optional[Dict]) -> str:
        """LLMæ•´å½¢å‡¦ç†ï¼ˆOllamaçµ±åˆç‰ˆï¼‰"""
        try:
            # Ollamaã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
            from new.services.llm import OllamaRefiner, OllamaClient
            
            # LLMè¨­å®šå–å¾—
            llm_model = settings.get('llm_model', 'phi4-mini')
            language = settings.get('language', 'ja')
            quality_threshold = settings.get('quality_threshold', 0.7)
            
            # ç„¡åŠ¹ãªãƒ¢ãƒ‡ãƒ«åãƒã‚§ãƒƒã‚¯ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ¤å®šï¼‰
            if 'invalid' in llm_model.lower():
                self.logger.info(f"ç„¡åŠ¹ãªãƒ¢ãƒ‡ãƒ«æŒ‡å®šæ¤œå‡º: {llm_model} â†’ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†")
                return self._fallback_text_refinement(text)
            
            # Ollamaæ¥ç¶šç¢ºèª
            client = OllamaClient(model=llm_model)
            is_available = await client.is_available()
            
            if not is_available:
                error_msg = f"âŒ Ollamaæ¥ç¶šå¤±æ•—: {client.base_url} (model: {llm_model})"
                self.logger.error(error_msg)
                raise RuntimeError(f"LLMå‡¦ç†ã‚¨ãƒ©ãƒ¼ - Ollamaã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“: {client.base_url}")
            
            refiner = OllamaRefiner(client)
            
            self.logger.info(f"LLMæ•´å½¢é–‹å§‹: ãƒ¢ãƒ‡ãƒ«={llm_model}, è¨€èª={language}")
            
            # å®Ÿéš›ã®Ollamaæ•´å½¢å®Ÿè¡Œï¼ˆå‡¦ç†æ™‚é–“æ¸¬å®šä»˜ãï¼‰
            ollama_start_time = time.perf_counter()
            refined_text, detected_lang, quality_score = await refiner.refine_text(
                raw_text=text,
                abort_flag=abort_flag,
                language=language,
                quality_threshold=quality_threshold
            )
            ollama_processing_time = time.perf_counter() - ollama_start_time
            
            self.logger.info(f"LLMæ•´å½¢å®Œäº†: å“è³ªã‚¹ã‚³ã‚¢={quality_score:.2f}, è¨€èª={detected_lang}, å‡¦ç†æ™‚é–“={ollama_processing_time:.1f}ç§’")
            
            return refined_text
                
        except ImportError as e:
            error_msg = f"âŒ Ollamaä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼: {e}"
            self.logger.error(error_msg)
            raise RuntimeError(f"LLMå‡¦ç†ã‚¨ãƒ©ãƒ¼ - Ollamaä¾å­˜é–¢ä¿‚ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {e}")
        except Exception as e:
            error_msg = f"âŒ LLMå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}"
            self.logger.error(error_msg)
            raise RuntimeError(f"LLMå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _create_llm_prompt(self, text: str, settings: Dict) -> str:
        """LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆï¼ˆé«˜å“è³ªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½¿ç”¨ï¼‰"""
        try:
            # çµ¶å¯¾importãƒ‘ã‚¹ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’å–å¾—
            import sys
            import os
            
            # ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
            workspace_root = '/workspace'
            if workspace_root not in sys.path:
                sys.path.insert(0, workspace_root)
            
            from new.services.llm.prompt_loader import get_prompt_loader
            
            language = settings.get('language', 'ja')
            
            # é«˜å“è³ªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰å–å¾—
            prompt_loader = get_prompt_loader()
            prompt_template = prompt_loader.load_prompt("refine_prompt_advanced", language)
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            prompt = prompt_loader.format_prompt(prompt_template, TEXT=text)
            
            self.logger.info(f"âœ… é«˜å“è³ªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½¿ç”¨æˆåŠŸ: {len(prompt_template)}æ–‡å­—, è¨€èª={language}")
            return prompt
            
        except Exception as e:
            self.logger.warning(f"âŒ é«˜å“è³ªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿å¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨: {e}")
            import traceback
            self.logger.debug(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç°¡æ˜“ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            language = settings.get('language', 'ja')
            quality_threshold = settings.get('quality_threshold', 0.7)
            
            prompt = f"""ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å“è³ªå‘ä¸Šã—ã¦ãã ã•ã„ã€‚

è¨€èª: {language}
å“è³ªé–¾å€¤: {quality_threshold}

åŸæ–‡:
{text}

ä¿®æ­£æŒ‡ç¤º:
- OCRèª¤å­—ãƒ»è„±å­—ã®ä¿®æ­£
- ä¸è‡ªç„¶ãªæ”¹è¡Œãƒ»ç©ºç™½ã®æ•´ç†
- æ–‡ç« æ§‹é€ ã®æ”¹å–„
- æ„å‘³ã‚’ä¿æŒã—ã¤ã¤èª­ã¿ã‚„ã™ãæ•´å½¢

ä¿®æ­£å¾Œãƒ†ã‚­ã‚¹ãƒˆ:"""
            
            return prompt

    def _fallback_text_refinement(self, text: str) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ†ã‚­ã‚¹ãƒˆæ•´å½¢ï¼ˆé«˜å“è³ªæ•´å½¢å‡¦ç†ï¼‰"""
        import re
        
        # å¤§å¹…ãªå“è³ªå‘ä¸Šå‡¦ç†
        # 1. Unicodeæ­£è¦åŒ–
        import unicodedata
        text = unicodedata.normalize('NFKC', text)
        
        # 2. OCRç‰¹æœ‰ã®èª¤èªè­˜ä¿®æ­£
        ocr_corrections = {
            # åŸºæœ¬çš„ãªèª¤å­—ä¿®æ­£
            r'(\d+)\s*å¹´\s*(\d+)\s*æœˆ\s*(\d+)\s*æ—¥': r'\1å¹´\2æœˆ\3æ—¥',
            r'æ ªå¼ä¼š\s*ç¤¾': 'æ ªå¼ä¼šç¤¾',
            r'æœ‰é™ä¼š\s*ç¤¾': 'æœ‰é™ä¼šç¤¾',
            r'ç ”ç©¶\s*æ‰€': 'ç ”ç©¶æ‰€',
            r'è©¦é¨“\s*ç‰‡': 'è©¦é¨“ç‰‡',
            r'æ\s*æ–™': 'ææ–™',
            r'å¼·\s*åº¦': 'å¼·åº¦',
            r'æ¸©\s*åº¦': 'æ¸©åº¦',
            r'æ¹¿\s*åº¦': 'æ¹¿åº¦',
            
            # æŠ€è¡“æ–‡æ›¸ç‰¹æœ‰ã®ä¿®æ­£
            r'kgf\s*/\s*mm': 'kgf/mm',
            r'N\s*/\s*mm': 'N/mm',
            r'MPa\s+': 'MPa ',
            r'Â°C\s+': 'Â°C ',
            r'ï¼…\s+': '% ',
            
            # æ•°å€¤ã¨å˜ä½ã®æ•´ç†
            r'(\d+)\s+([a-zA-Z]+)': r'\1\2',  # æ•°å€¤ã¨è‹±å­—å˜ä½ã®é–“ã®ç©ºç™½
            r'(\d+)\s*Ã—\s*(\d+)': r'\1Ã—\2',  # ä¹—ç®—è¨˜å·ã®æ•´ç†
            
            # æ—¥æœ¬èªæ–‡ç« ã®æ•´ç†
            r'([ã‚-ã‚“])\s+([ã‚-ã‚“])': r'\1\2',  # ã²ã‚‰ãŒãªé–“ã®ä¸è¦ãªç©ºç™½
            r'([ã‚¢-ãƒ³])\s+([ã‚¢-ãƒ³])': r'\1\2',  # ã‚«ã‚¿ã‚«ãƒŠé–“ã®ä¸è¦ãªç©ºç™½
            r'([ä¸€-é¾¯])\s+([ä¸€-é¾¯])': r'\1\2',  # æ¼¢å­—é–“ã®ä¸è¦ãªç©ºç™½
        }
        
        for pattern, replacement in ocr_corrections.items():
            text = re.sub(pattern, replacement, text)
        
        # 3. å¤§å¹…ãªç©ºç™½ãƒ»æ”¹è¡Œæ•´ç†
        lines = text.split('\n')
        processed_lines = []
        
        for line in lines:
            # å„è¡Œã®å‡¦ç†
            line = line.strip()
            
            # ç©ºè¡Œã®ã‚¹ã‚­ãƒƒãƒ—
            if not line:
                if processed_lines and processed_lines[-1] != '':
                    processed_lines.append('')
                continue
            
            # éåº¦ãªç©ºç™½ã®å‰Šé™¤ï¼ˆé€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«ï¼‰
            line = re.sub(r'[ \t]{2,}', ' ', line)
            line = re.sub(r'[\u3000]{2,}', 'ã€€', line)
            
            # æ–‡ç« æ§‹é€ ã®æ”¹å–„
            # é …ç•ªã®æ•´ç†
            line = re.sub(r'^(\d+)\s*[.ï¼]\s*', r'\1. ', line)
            
            # ã‚«ãƒƒã‚³ã®æ•´ç†
            line = re.sub(r'\s*ï¼ˆ\s*', 'ï¼ˆ', line)
            line = re.sub(r'\s*ï¼‰\s*', 'ï¼‰', line)
            line = re.sub(r'\s*\(\s*', 'ï¼ˆ', line)
            line = re.sub(r'\s*\)\s*', 'ï¼‰', line)
            
            processed_lines.append(line)
        
        # 4. æ–‡æ›¸å…¨ä½“ã®æ§‹é€ æ”¹å–„
        result = '\n'.join(processed_lines)
        
        # é€£ç¶šã™ã‚‹ç©ºè¡Œã‚’æœ€å¤§2è¡Œã«åˆ¶é™
        result = re.sub(r'\n{3,}', '\n\n', result)
        
        # 5. å¥èª­ç‚¹ã®æ­£è¦åŒ–
        result = re.sub(r'[ã€ï¼Œ]', 'ã€', result)
        result = re.sub(r'[ã€‚ï¼]', 'ã€‚', result)
        
        # 6. å ±å‘Šæ›¸ç‰¹æœ‰ã®æ•´å½¢
        # è¦‹å‡ºã—ã¨å†…å®¹ã®åˆ†é›¢æ”¹å–„
        result = re.sub(r'^([^\n]{1,30}ï¼š)(\S)', r'\1\n\2', result, flags=re.MULTILINE)
        
        # è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ã®æ•´ç†
        result = re.sub(r'(\w+)\s+(\w+)\s+(\w+)', r'\1ã€€\2ã€€\3', result)
        
        self.logger.info(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ•´å½¢: {len(text)}æ–‡å­— â†’ {len(result)}æ–‡å­— (å·®åˆ†: {len(result)-len(text)}æ–‡å­—)")
        
        return result.strip()
    
    async def _process_embedding(self, text: str, settings: Dict, abort_flag: Optional[Dict]) -> Dict:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†ï¼ˆæ¨¡æ“¬å®Ÿè£…ï¼‰"""
        try:
            await asyncio.sleep(1.0)  # ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            
            # ä¸­æ–­ãƒã‚§ãƒƒã‚¯
            if abort_flag and abort_flag.get('flag', False):
                return {'success': False, 'models': []}
            
            # æ¨¡æ“¬å®Ÿè£…
            embedding_models = settings.get('embedding_models', ['intfloat-e5-large-v2'])
            
            return {
                'success': True,
                'models': embedding_models,
                'vector_count': len(text.split()) // 10  # æ¨¡æ“¬ãƒ™ã‚¯ãƒˆãƒ«æ•°
            }
            
        except Exception as e:
            self.logger.error(f"ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return {'success': False, 'models': []}
    
    async def _save_to_database(self, file_id: str, raw_text: str, refined_text: str, settings: Dict):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        try:
            conn = DB_ENGINE.connect()
            try:
                from sqlalchemy import text
                
                # files_textãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜/æ›´æ–°
                query = text("""
                    INSERT INTO files_text (blob_id, raw_text, refined_text, quality_score, updated_at)
                    VALUES (:blob_id, :raw_text, :refined_text, :quality_score, NOW())
                    ON CONFLICT (blob_id) 
                    DO UPDATE SET 
                        raw_text = EXCLUDED.raw_text,
                        refined_text = EXCLUDED.refined_text,
                        quality_score = EXCLUDED.quality_score,
                        updated_at = NOW()
                """)
                
                conn.execute(query, {
                    'blob_id': file_id,
                    'raw_text': raw_text,
                    'refined_text': refined_text,
                    'quality_score': 0.8  # æ¨¡æ“¬å“è³ªã‚¹ã‚³ã‚¢
                })
                conn.commit()
                
            finally:
                conn.close()
                
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼ [{file_id}]: {e}")
            raise
    
    async def _emit_progress(self, callback: Optional[callable], file_name: str, step: str, progress: int):
        """é€²æ—é€šçŸ¥ã‚’é€å‡º"""
        if callback is None:
            return  # callbackãŒNoneã®å ´åˆã¯ä½•ã‚‚ã—ãªã„
            
        try:
            # callbackãŒé€šå¸¸ã®é–¢æ•°ã‹asyncé–¢æ•°ã‹ã‚’åˆ¤å®š
            import asyncio
            result = callback({
                'file_name': file_name,
                'step': step,
                'progress': progress
            })
            # asyncé–¢æ•°ã®å ´åˆã®ã¿await
            if asyncio.iscoroutine(result):
                await result
        except Exception as e:
            self.logger.error(f"é€²æ—é€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _emit_progress_with_data(self, callback: Optional[callable], event_data: Dict):
        """è©³ç´°ãƒ‡ãƒ¼ã‚¿ä»˜ãé€²æ—é€šçŸ¥ã‚’é€å‡º"""
        if callback is None:
            return  # callbackãŒNoneã®å ´åˆã¯ä½•ã‚‚ã—ãªã„
            
        try:
            # callbackãŒé€šå¸¸ã®é–¢æ•°ã‹asyncé–¢æ•°ã‹ã‚’åˆ¤å®š
            import asyncio
            result = callback(event_data)
            # asyncé–¢æ•°ã®å ´åˆã®ã¿await
            if asyncio.iscoroutine(result):
                await result
        except Exception as e:
            self.logger.error(f"è©³ç´°é€²æ—é€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")