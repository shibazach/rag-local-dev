#!/usr/bin/env python3
# new/services/search_service.py
# æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹

import logging
import json
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_

from ..models import File, FileText, Embedding, FileImage
from ..config import LOGGER
from .embedding_service import EmbeddingService

class SearchService:
    """æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        self.embedding_service = EmbeddingService()
    
    def search_text(self, db: Session, query: str, top_k: int = 5, file_ids: List[str] = None) -> List[Dict[str, Any]]:
        """ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢"""
        try:
            LOGGER.info(f"ğŸ” ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢é–‹å§‹: ã‚¯ã‚¨ãƒª='{query}', top_k={top_k}")
            
            # ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            query_embedding = self.embedding_service.create_embeddings([query])[0]
            
            # æ¤œç´¢å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            query_conditions = [Embedding.embedding_vector.isnot(None)]
            if file_ids:
                query_conditions.append(Embedding.file_id.in_(file_ids))
            
            embeddings = db.query(Embedding).filter(and_(*query_conditions)).all()
            
            if not embeddings:
                LOGGER.warning("æ¤œç´¢å¯¾è±¡ã®ãƒ™ã‚¯ãƒˆãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return []
            
            # é¡ä¼¼åº¦è¨ˆç®—
            similarities = []
            for embedding in embeddings:
                try:
                    embedding_vector = json.loads(embedding.embedding_vector)
                    similarity = self.embedding_service.calculate_similarity(query_embedding, embedding_vector)
                    
                    similarities.append({
                        "file_id": str(embedding.file_id),
                        "chunk_id": embedding.chunk_id,
                        "text_chunk": embedding.text_chunk,
                        "similarity": similarity,
                        "embedding_model": embedding.embedding_model
                    })
                except Exception as e:
                    LOGGER.warning(f"é¡ä¼¼åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            # é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆ
            similarities.sort(key=lambda x: x["similarity"], reverse=True)
            
            # top_kã‚’è¿”ã™
            results = similarities[:top_k]
            
            LOGGER.info(f"ğŸ‰ ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢å®Œäº†: {len(results)}ä»¶")
            return results
            
        except Exception as e:
            LOGGER.error(f"ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def search_images(self, db: Session, query: str, top_k: int = 5, file_ids: List[str] = None) -> List[Dict[str, Any]]:
        """ç”»åƒæ¤œç´¢"""
        try:
            LOGGER.info(f"ğŸ–¼ï¸ ç”»åƒæ¤œç´¢é–‹å§‹: ã‚¯ã‚¨ãƒª='{query}', top_k={top_k}")
            
            # ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            query_embedding = self.embedding_service.create_embeddings([query])[0]
            
            # æ¤œç´¢å¯¾è±¡ã®ç”»åƒã‚’å–å¾—
            query_conditions = [FileImage.embedding_vector.isnot(None)]
            if file_ids:
                query_conditions.append(FileImage.file_id.in_(file_ids))
            
            images = db.query(FileImage).filter(and_(*query_conditions)).all()
            
            if not images:
                LOGGER.warning("æ¤œç´¢å¯¾è±¡ã®ç”»åƒãƒ™ã‚¯ãƒˆãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return []
            
            # é¡ä¼¼åº¦è¨ˆç®—
            similarities = []
            for image in images:
                try:
                    embedding_vector = json.loads(image.embedding_vector)
                    similarity = self.embedding_service.calculate_similarity(query_embedding, embedding_vector)
                    
                    similarities.append({
                        "file_id": str(image.file_id),
                        "page_number": image.page_number,
                        "image_number": image.image_number,
                        "ocr_text": image.ocr_text,
                        "llm_description": image.llm_description,
                        "similarity": similarity,
                        "embedding_model": image.embedding_model
                    })
                except Exception as e:
                    LOGGER.warning(f"ç”»åƒé¡ä¼¼åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            # é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆ
            similarities.sort(key=lambda x: x["similarity"], reverse=True)
            
            # top_kã‚’è¿”ã™
            results = similarities[:top_k]
            
            LOGGER.info(f"ğŸ‰ ç”»åƒæ¤œç´¢å®Œäº†: {len(results)}ä»¶")
            return results
            
        except Exception as e:
            LOGGER.error(f"ç”»åƒæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def hybrid_search(self, db: Session, query: str, top_k: int = 10, file_ids: List[str] = None) -> Dict[str, Any]:
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆãƒ†ã‚­ã‚¹ãƒˆ + ç”»åƒï¼‰"""
        try:
            LOGGER.info(f"ğŸ” ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢é–‹å§‹: ã‚¯ã‚¨ãƒª='{query}', top_k={top_k}")
            
            # ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢
            text_results = self.search_text(db, query, top_k // 2, file_ids)
            
            # ç”»åƒæ¤œç´¢
            image_results = self.search_images(db, query, top_k // 2, file_ids)
            
            # çµæœã‚’çµ±åˆ
            all_results = []
            
            # ãƒ†ã‚­ã‚¹ãƒˆçµæœã‚’è¿½åŠ 
            for result in text_results:
                result["type"] = "text"
                all_results.append(result)
            
            # ç”»åƒçµæœã‚’è¿½åŠ 
            for result in image_results:
                result["type"] = "image"
                all_results.append(result)
            
            # é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆ
            all_results.sort(key=lambda x: x["similarity"], reverse=True)
            
            # top_kã‚’è¿”ã™
            final_results = all_results[:top_k]
            
            # çµ±è¨ˆæƒ…å ±
            text_count = len([r for r in final_results if r["type"] == "text"])
            image_count = len([r for r in final_results if r["type"] == "image"])
            
            stats = {
                "total_results": len(final_results),
                "text_results": text_count,
                "image_results": image_count,
                "avg_similarity": sum(r["similarity"] for r in final_results) / len(final_results) if final_results else 0.0
            }
            
            LOGGER.info(f"ğŸ‰ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢å®Œäº†: {len(final_results)}ä»¶ (ãƒ†ã‚­ã‚¹ãƒˆ:{text_count}, ç”»åƒ:{image_count})")
            
            return {
                "results": final_results,
                "stats": stats
            }
            
        except Exception as e:
            LOGGER.error(f"ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return {"results": [], "stats": {}}
    
    def get_file_summary(self, db: Session, file_id: str) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢ã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
            file = db.query(File).filter(File.id == file_id).first()
            if not file:
                return {}
            
            # ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
            file_text = db.query(FileText).filter(FileText.file_id == file_id).first()
            
            # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«æ•°
            embedding_count = db.query(Embedding).filter(Embedding.file_id == file_id).count()
            
            # ç”»åƒæ•°
            image_count = db.query(FileImage).filter(FileImage.file_id == file_id).count()
            
            return {
                "file_id": str(file.id),
                "file_name": file.file_name,
                "file_size": file.file_size,
                "status": file.status,
                "processing_stage": file.processing_stage,
                "text_chunks": len(file_text.text_chunks) if file_text and file_text.text_chunks else 0,
                "embeddings": embedding_count,
                "images": image_count,
                "created_at": file.created_at.isoformat() if file.created_at else None
            }
            
        except Exception as e:
            LOGGER.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒãƒªãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def get_search_statistics(self, db: Session) -> Dict[str, Any]:
        """æ¤œç´¢çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ï¼ˆæ–°DBè¨­è¨ˆå¯¾å¿œï¼‰"""
        try:
            from sqlalchemy import text as sql_text
            from ..db_handler import get_all_files
            
            # æ–°ã—ã„DBãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
            files = get_all_files()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æ•°
            total_files = len(files)
            
            # å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°ï¼ˆfiles_textãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‚‚ã®ï¼‰
            processed_files = len([f for f in files if f["status"] == "processed"])
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯æ•°ï¼ˆembeddingsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—ï¼‰
            total_chunks_query = db.execute(sql_text("SELECT COUNT(*) FROM embeddings"))
            total_chunks = total_chunks_query.scalar() or 0
            
            # ç”»åƒæ•°ï¼ˆå‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¨å®š - å®Ÿéš›ã®ç”»åƒãƒ†ãƒ¼ãƒ–ãƒ«ã¯åˆ¥é€”å®Ÿè£…äºˆå®šï¼‰
            total_images = 0  # ä¸€æ™‚çš„ã«0ã¨ã™ã‚‹
            
            # ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°ï¼ˆembeddingsãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
            vectorized_files_query = db.execute(sql_text("""
                SELECT COUNT(DISTINCT blob_id) FROM embeddings WHERE blob_id IS NOT NULL
            """))
            vectorized_files = vectorized_files_query.scalar() or 0
            
            # å‡¦ç†ç‡è¨ˆç®—
            processing_rate = (processed_files / total_files * 100) if total_files > 0 else 0.0
            
            LOGGER.debug(f"ğŸ“Š çµ±è¨ˆæƒ…å ±: ãƒ•ã‚¡ã‚¤ãƒ«={total_files}, å‡¦ç†æ¸ˆã¿={processed_files}, ãƒãƒ£ãƒ³ã‚¯={total_chunks}, ç”»åƒ={total_images}")
            
            return {
                "total_files": total_files,
                "processed_files": processed_files,
                "total_chunks": total_chunks,
                "total_images": total_images,
                "vectorized_files": vectorized_files,
                "processing_rate": processing_rate
            }
            
        except Exception as e:
            LOGGER.error(f"æ¤œç´¢çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "total_files": 0,
                "processed_files": 0,
                "total_chunks": 0,
                "total_images": 0,
                "vectorized_files": 0,
                "processing_rate": 0.0
            } 