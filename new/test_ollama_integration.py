#!/usr/bin/env python3
# new/test_ollama_integration.py
"""
Ollamaçµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
LLMæ¥ç¶šã€ãƒ†ã‚­ã‚¹ãƒˆæ•´å½¢ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’æ¤œè¨¼
"""

import asyncio
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆè¿½åŠ 
sys.path.append(str(Path(__file__).parent))

from services.llm import OllamaClient, OllamaRefiner
from services.processing import FileProcessor
from config import LOGGER


async def test_ollama_connection():
    """Ollamaæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
    print("ğŸ”— Ollamaæ¥ç¶šãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    try:
        client = OllamaClient()
        is_available = await client.is_available()
        
        if is_available:
            print("  âœ… Ollamaæ¥ç¶šæˆåŠŸ")
            return True
        else:
            print("  âŒ Ollamaæ¥ç¶šå¤±æ•—ï¼ˆã‚µãƒ¼ãƒãƒ¼æœªèµ·å‹•ã®å¯èƒ½æ€§ï¼‰")
            return False
            
    except ImportError as e:
        print(f"  âŒ ä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼: {e}")
        print("     pip install langchain langchain-community langchain-ollama")
        return False
    except Exception as e:
        print(f"  âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return False


async def test_text_refinement():
    """ãƒ†ã‚­ã‚¹ãƒˆæ•´å½¢ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§  ãƒ†ã‚­ã‚¹ãƒˆæ•´å½¢ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
    test_text = """
    ã“ã‚Œã¯    OCRã§èª­ã¿å–ã£ãŸ
    
    
    ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚
    
    æ”¹è¡Œã‚„     ã‚¹ãƒšãƒ¼ã‚¹ãŒ
    
    
    ä¸è¦å‰‡ã«     ãªã£ã¦ã„ã¾ã™ã€‚
    """
    
    try:
        refiner = OllamaRefiner()
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
        print("  ğŸ“ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
        fallback_result = refiner.normalize_text(test_text)
        print(f"     æ­£è¦åŒ–çµæœ: {repr(fallback_result[:50])}...")
        
        # Ollamaæ•´å½¢ãƒ†ã‚¹ãƒˆ
        print("  ğŸ¤– Ollamaæ•´å½¢ãƒ†ã‚¹ãƒˆ")
        refined_text, language, quality_score = await refiner.refine_text(
            raw_text=test_text,
            language="ja"
        )
        
        print(f"     æ•´å½¢çµæœ: {repr(refined_text[:50])}...")
        print(f"     è¨€èª: {language}")
        print(f"     å“è³ªã‚¹ã‚³ã‚¢: {quality_score:.2f}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ æ•´å½¢ã‚¨ãƒ©ãƒ¼: {e}")
        return False


async def test_processing_pipeline():
    """å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆãƒ†ã‚¹ãƒˆ"""
    print("\nâš™ï¸ å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    try:
        processor = FileProcessor()
        
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        test_file_path = "/tmp/test_ollama.txt"
        test_content = "ã“ã‚Œã¯Ollamaçµ±åˆãƒ†ã‚¹ãƒˆç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚LLMã«ã‚ˆã‚‹æ•´å½¢ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚"
        
        with open(test_file_path, 'w', encoding='utf-8') as f:
            f.write(test_content)
        
        print(f"  ğŸ“„ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {test_file_path}")
        
        # å‡¦ç†è¨­å®š
        settings = {
            'llm_model': 'phi4-mini',
            'language': 'ja',
            'quality_threshold': 0.7,
            'embedding_models': ['intfloat-e5-large-v2']
        }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Ÿè¡Œï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ãªã—ï¼‰
        print("  ğŸ”„ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Ÿè¡Œ")
        result = await processor.process_file(
            file_id="test-ollama-001",
            file_name="test_ollama.txt",
            file_path=test_file_path,
            settings=settings,
            save_to_db=False  # ãƒ†ã‚¹ãƒˆç”¨ã«DBä¿å­˜ã‚¹ã‚­ãƒƒãƒ—
        )
        
        print("  ğŸ“Š å‡¦ç†çµæœ:")
        print(f"     æˆåŠŸ: {result.get('success', False)}")
        print(f"     OCRãƒ†ã‚­ã‚¹ãƒˆ: {repr(result.get('ocr_result', {}).get('text', '')[:50])}...")
        print(f"     LLMæ•´å½¢æ¸ˆã¿: {repr(result.get('llm_refined_text', '')[:50])}...")
        print(f"     å“è³ªã‚¹ã‚³ã‚¢: {result.get('quality_score', 0):.2f}")
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        Path(test_file_path).unlink(missing_ok=True)
        
        return result.get('success', False)
        
    except Exception as e:
        print(f"  âŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        return False


async def test_error_handling():
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ›¡ï¸ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    try:
        # ä¸æ­£ãªãƒ¢ãƒ‡ãƒ«æŒ‡å®š
        print("  ğŸ”§ ä¸æ­£ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ")
        client = OllamaClient(model="invalid-model-name")
        try:
            result = await client.generate_text("ãƒ†ã‚¹ãƒˆ")
            print(f"     äºˆæœŸã—ãªã„æˆåŠŸ: {result[:30]}...")
        except Exception as e:
            print(f"     æœŸå¾…é€šã‚Šã®ã‚¨ãƒ©ãƒ¼: {type(e).__name__}")
        
        # ä¸­æ–­ãƒ•ãƒ©ã‚°ãƒ†ã‚¹ãƒˆ
        print("  â¹ï¸ ä¸­æ–­ãƒ•ãƒ©ã‚°ãƒ†ã‚¹ãƒˆ")
        refiner = OllamaRefiner()
        abort_flag = {'flag': True}
        
        try:
            result = await refiner.refine_text("ãƒ†ã‚¹ãƒˆ", abort_flag=abort_flag)
            print(f"     ä¸­æ–­çµæœ: {result[:30]}...")
        except InterruptedError:
            print("     æ­£å¸¸ãªä¸­æ–­å‡¦ç†")
        
        return True
        
    except Exception as e:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        return False


async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ Ollamaçµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 50)
    
    tests = [
        ("Ollamaæ¥ç¶š", test_ollama_connection),
        ("ãƒ†ã‚­ã‚¹ãƒˆæ•´å½¢", test_text_refinement),
        ("å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³", test_processing_pipeline),
        ("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°", test_error_handling),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = await test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name}ãƒ†ã‚¹ãƒˆä¾‹å¤–: {e}")
            results.append((test_name, False))
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 50)
    print("ğŸ“Š Ollamaçµ±åˆãƒ†ã‚¹ãƒˆçµæœ")
    print("=" * 50)
    
    success_count = 0
    total_count = len(results)
    
    for test_name, success in results:
        status = "âœ…" if success else "âŒ"
        print(f"{status} {test_name}: {'æˆåŠŸ' if success else 'å¤±æ•—'}")
        if success:
            success_count += 1
    
    success_rate = (success_count / total_count) * 100
    print(f"\nğŸ“ˆ æˆåŠŸç‡: {success_count}/{total_count} ({success_rate:.1f}%)")
    
    if success_rate >= 75:
        print("ğŸ‰ Ollamaçµ±åˆãƒ†ã‚¹ãƒˆå…¨ä½“: âœ… æˆåŠŸ")
        return True
    else:
        print("âš ï¸ Ollamaçµ±åˆãƒ†ã‚¹ãƒˆå…¨ä½“: âŒ è¦æ”¹å–„")
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)