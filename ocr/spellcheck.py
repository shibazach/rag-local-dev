# ocr/spellcheck.py
# OCRèª¤å­—è£œæ­£ã®æ±ç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import os, csv
import MeCab

from src import bootstrap
from src.config import MECAB_DICT_PATH
from src.utils import debug_print

 # âœ… ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåŸºæº–
base_dir = os.path.dirname(__file__) 

# --- known_wordsã‚’è¤‡æ•°CSVã‹ã‚‰èª­ã¿è¾¼ã¿ ---
def load_known_words(csv_paths):
    words = set()
    for path in csv_paths:
        abs_path = os.path.join(base_dir, path)
        with open(abs_path, encoding="utf-8") as f:
            reader = csv.reader(f)
            for row in reader:
                if row and row[0].strip():
                    words.add(row[0].strip())
    return words

# --- èª¤å­—è¾æ›¸ã‚’CSVã‹ã‚‰èª­ã¿è¾¼ã¿ ---
def load_kanji_mistakes(csv_path):
    mapping = {}
    abs_path = os.path.join(base_dir, csv_path)

    with open(abs_path, encoding="utf-8") as f:
        reader = csv.reader(f)
        next(reader, None)
        for row in reader:
            if len(row) >= 2:
                wrong, correct = row[0].strip(), row[1].strip()
                if wrong and correct:
                    mapping[wrong] = correct
    return mapping

# --- MeCabåˆ†ã‹ã¡æ›¸ã ---
def tokenize(text):
    try:
        mecab = MeCab.Tagger(f"-d {MECAB_DICT_PATH} -Owakati")
        return mecab.parse(text).strip().split()
    except RuntimeError as e:
        debug_print(f"âŒ MeCabã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        debug_print(f"ğŸ‘‰ config.py ã® MECAB_DICT_PATH ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆç¾åœ¨: {MECAB_DICT_PATH}ï¼‰")
        raise

# --- ãƒ¡ã‚¤ãƒ³è£œæ­£é–¢æ•° ---
def correct_text(text,
                 known_word_paths=["dic/known_words_common.csv", "dic/known_words_custom.csv"],
                 kanji_mistakes_path="dic/ocr_word_mistakes.csv"):
    known_words = load_known_words(known_word_paths)
    kanji_mistakes = load_kanji_mistakes(kanji_mistakes_path)
    for wrong, correct in kanji_mistakes.items():
        if wrong not in known_words:
            text = text.replace(wrong, correct)
    return text
