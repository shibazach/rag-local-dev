#!/usr/bin/env bash
# REM: Ollama install / model preload / systemd åŒ– / logrotate è¨­å®š
# REM: å®Ÿè¡Œã¯ root å‰æ (sudo -i ã§å…¥ã£ã¦ã‹ã‚‰å©ãæƒ³å®š)
# REM: ragapp ãªã© Docker å´ã¯ host.docker.internal:11434 ã§æŽ¥ç¶š

set -euo pipefail

### ---- å…±é€šé–¢æ•° ---------------------------------------------------------
# REM: ã‚³ãƒžãƒ³ãƒ‰å­˜åœ¨ãƒã‚§ãƒƒã‚¯
command_exists() { command -v "$1" &>/dev/null; }

### ---- 1. ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å‰ææ¡ä»¶ -------------------------------------------
echo "ðŸ§© [1/5] Installing prerequisite packagesâ€¦"
apt-get update -qq
apt-get install -yq curl jq logrotate

### ---- 2. Ollama ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« ------------------------------------------
echo "ðŸ§  [2/5] Installing Ollama (if needed)â€¦"
if ! command_exists ollama; then
  curl -fsSL https://ollama.com/install.sh | bash
else
  echo "âœ… Ollama already installed."
fi

### ---- 3. ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™ ----------------------------------------
echo "ðŸ“ [3/5] Preparing log directoryâ€¦"
mkdir -p /var/log/ollama
touch /var/log/ollama/ollama.log
chown root:root /var/log/ollama

### ---- 3.5 ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™ -----------------------------------
echo "ðŸ“ [3.5/5] Ensuring Ollama model directory existsâ€¦"
# Ollama ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ path ã‚’ãã®ã¾ã¾ä½¿ã†
mkdir -p /usr/share/ollama/.ollama/models
chown -R ollama:ollama /usr/share/ollama/.ollama

### ---- 4. ãƒ¢ãƒ‡ãƒ«ã‚ã‚‰ã‹ã˜ã‚å–å¾— ----------------------------------------
echo "ðŸ“¦ [4/5] Pulling required models (may take a while)â€¦"
#export OLLAMA_MODELS=/usr/share/ollama/.ollama/models
#ollama pull phi4-mini        || true
#ollama pull nomic-embed-text || true

sudo -u ollama env \
  HOME=/home/ollama \
  OLLAMA_MODELS=/usr/share/ollama/.ollama/models \
  OLLAMA_DEBUG=1 \
  ollama pull phi4-mini        || true
sudo -u ollama env \
  HOME=/home/ollama \
  OLLAMA_MODELS=/usr/share/ollama/.ollama/models \
  OLLAMA_DEBUG=1 \
  ollama pull nomic-embed-text || true

### ---- 5. systemd ãƒ¦ãƒ‹ãƒƒãƒˆç”Ÿæˆ ----------------------------------------
echo "ðŸ”§ [5/5] Creating systemd unit /etc/systemd/system/ollama.service"
cat >/etc/systemd/system/ollama.service <<'EOF'
[Unit]
Description=Ollama Service
After=network-online.target
Wants=network-online.target

[Service]
# Environment=HOME=/root
# Environment=OLLAMA_DEBUG=1
# Environment=OLLAMA_MODELS=/usr/share/ollama/.ollama/models
# Environment=OLLAMA_HOST=0.0.0.0:11434
# Environment=OLLAMA_ORIGINS=*

# ã“ã“ã§ env ã‚’ä½¿ã£ã¦ç¢ºå®Ÿã«ç’°å¢ƒã‚’æ¸¡ã™
ExecStart=
ExecStart=/usr/bin/env \
  HOME=/root \
  OLLAMA_MODELS=/usr/share/ollama/.ollama/models \
  OLLAMA_HOST=0.0.0.0:11434 \
  OLLAMA_ORIGINS=* \
  /usr/local/bin/ollama serve \
    --host 0.0.0.0 \
    --port 11434 \
    --origins '*'

StandardOutput=append:/var/log/ollama/ollama.log
StandardError=inherit
MemoryMax=16G
Restart=always
RestartSec=3

[Install]
WantedBy=multi-user.target
EOF

# systemd å†èª­ã¿è¾¼ã¿ & èµ·å‹•
echo "ðŸ”„ Reload and start Ollama serviceâ€¦"
systemctl daemon-reload
echo "Enabling Ollama serviceâ€¦"
systemctl enable --now ollama

echo "ðŸŽ‰ Ollama setup complete! é€£æºå…ˆã¯ http://host.docker.internal:11434 ã§ã™ã€‚"
