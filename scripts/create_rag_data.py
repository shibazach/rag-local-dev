# scripts/create_rag_data.py
# REM: .eml ãƒ•ã‚¡ã‚¤ãƒ«ã‚„å„ç¨®æ–‡æ›¸ã‚’ OCRâ†’LLMæ•´å½¢â†’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç™»éŒ²ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
import os
import glob
import datetime
from email import policy
from email.parser import BytesParser

from src.extractor import extract_text_by_extension
from scripts.llm_text_refiner import refine_text_with_llm
from src.file_embedder import embed_and_insert
from src.config import EMBEDDING_OPTIONS, INPUT_DIR, LOG_DIR, DEVELOPMENT_MODE

from src import bootstrap  # ãƒ‘ã‚¹ç¢ºä¿ã®ã¿
from src.error_handler import install_global_exception_handler

# REM: ä¾‹å¤–ç™ºç”Ÿæ™‚ã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«ãƒ­ã‚°ã‚’è¨˜éŒ²
install_global_exception_handler()

# REM: è‹±èªèª¤åæ˜ ãªã©ã‚’åˆ¤å®šã™ã‚‹å…¸å‹ãƒ‘ã‚¿ãƒ¼ãƒ³
TEMPLATE_PATTERNS = [
    "certainly", "please provide", "reformat", "i will help",
    "note that this is a translation", "based on your ocr output"
]

def is_invalid_llm_output(text: str) -> bool:
    from langdetect import detect
    if len(text.strip()) < 30:
        return True
    lower = text.lower()
    if any(p in lower for p in TEMPLATE_PATTERNS):
        return True
    try:
        if detect(text) == "en":
            return True
    except Exception:
        return True
    return False

def extract_text_from_eml(filepath: str) -> list[str]:
    with open(filepath, "rb") as f:
        msg = BytesParser(policy=policy.default).parse(f)
    subject = msg.get("subject", "")
    date = msg.get("date", "")
    body = ""
    if msg.is_multipart():
        for part in msg.walk():
            if part.get_content_type() == "text/plain":
                try:
                    body += part.get_content()
                except Exception:
                    payload = part.get_payload(decode=True) or b""
                    body += payload.decode(errors="ignore")
    else:
        try:
            body = msg.get_content()
        except Exception:
            payload = msg.get_payload(decode=True) or b""
            body = payload.decode(errors="ignore")
    header = f"Subject: {subject}\nDate: {date}\n"
    return [header + "\n" + body]

def log_full_processing(filepath, refined_ja, refined_en,
                        ja_chunks, en_chunks,
                        ja_embeddings, en_embeddings):
    log_dir = LOG_DIR
    os.makedirs(log_dir, exist_ok=True)
    base = os.path.splitext(os.path.basename(filepath))[0]
    log_path = os.path.join(log_dir, f"{base}.log")
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(log_path, "w", encoding="utf-8") as f:
        f.write(f"ğŸ“… å®Ÿè¡Œæ—¥æ™‚: {now}\nğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«: {filepath}\n\n")
        f.write(f"ğŸ§  æ—¥æœ¬èªãƒãƒ£ãƒ³ã‚¯æ•°: {len(ja_embeddings)}\n")
        f.write(f"ğŸ§  è‹±èªãƒãƒ£ãƒ³ã‚¯æ•°: {len(en_embeddings)}\n\n")
        f.write("=== ğŸ“ æ•´å½¢æ¸ˆã¿ï¼ˆæ—¥æœ¬èªï¼‰ ===\n" + refined_ja + "\n\n")
        f.write("=== âœ‚ï¸ æ—¥æœ¬èªãƒãƒ£ãƒ³ã‚¯ä¸€è¦§ ===\n" +
                "\n".join(f"[{i+1}] {c}" for i, c in enumerate(ja_chunks)) + "\n\n")
        f.write("=== ğŸŒ æ•´å½¢æ¸ˆã¿ï¼ˆè‹±èªï¼‰ ===\n" + refined_en + "\n\n")
        f.write("=== âœ‚ï¸ è‹±èªãƒãƒ£ãƒ³ã‚¯ä¸€è¦§ ===\n" +
                "\n".join(f"[{i+1}] {c}" for i, c in enumerate(en_chunks)))
    print(f"ğŸ“¦ å‡¦ç†ãƒ­ã‚°å‡ºåŠ›: {log_path}")

def process_file(filepath: str) -> None:
    print(f"\nğŸ“„ å‡¦ç†ä¸­: {filepath}")
    try:
        ext = os.path.splitext(filepath)[1].lower()
        texts = extract_text_from_eml(filepath) if ext == ".eml" else extract_text_by_extension(filepath)
        joined = "\n".join(texts).strip()
        if not joined or any(p in joined.lower() for p in TEMPLATE_PATTERNS):
            raise ValueError("ç„¡åŠ¹ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆç©ºã¾ãŸã¯è‹±èªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç–‘ã„ï¼‰")

        print("\nğŸ” æŠ½å‡ºåŸæ–‡ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®20è¡Œï¼‰:")
        for i, line in enumerate(joined.splitlines()[:20]):
            print(f"{i+1:>2}: {line}")
        if len(joined.splitlines()) > 20:
            print("...ï¼ˆä»¥ä¸‹çœç•¥ï¼‰")
        print("="*40)

        print("ğŸ§  LLMæ•´å½¢ï¼ˆphi4-miniï¼‰å®Ÿè¡Œä¸­â€¦")
        refined_ja, lang, score = refine_text_with_llm(joined, model="phi4-mini")
        if is_invalid_llm_output(refined_ja):
            raise ValueError("æ•´å½¢çµæœãŒä¸æ­£ã¨åˆ¤æ–­ã•ã‚Œã¾ã—ãŸ")
        print(f"ğŸ“Š æ•´å½¢å“è³ªã‚¹ã‚³ã‚¢: {score:.2f}")

        # REM: embed_and_insert å†…ã§ insert_file_and_get_idï½upsert_content ã¾ã§å®Ÿè¡Œ
        ja_chunks, ja_embeddings = embed_and_insert(
            texts=[joined, refined_ja],
            filepath=filepath,
            model_keys=list(EMBEDDING_OPTIONS.keys()),
            return_data=True,
            quality_score=score,
            ocr_raw_text=joined
        )

        refined_en, en_chunks, en_embeddings = "", [], []

        log_full_processing(
            filepath,
            refined_ja, refined_en,
            ja_chunks, en_chunks,
            ja_embeddings, en_embeddings
        )
        print("âœ… å®Œäº†")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

def main(input_folder: str = INPUT_DIR) -> None:
    # REM: å¿…è¦ã«å¿œã˜ã¦ GUI ã‹ã‚‰å‘¼ã³å‡ºã™å…¥å£ã¨ã—ã¦æ®‹ã™
    patterns = ("*.pdf", "*.docx", "*.txt", "*.csv", "*.json", "*.eml")
    files = []
    for pat in patterns:
        files.extend(glob.glob(os.path.join(input_folder, pat)))
    total = len(files)
    for idx, filepath in enumerate(files, start=1):
        process_file(filepath)
