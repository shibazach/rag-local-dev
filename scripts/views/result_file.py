# REM: ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ãƒ¢ãƒ¼ãƒ‰ã®æ¤œç´¢ â†’ è¦ç´„ï¼‹ä¸€è‡´åº¦è¡¨ç¤º
# scripts/views/result_file.py
import streamlit as st
import streamlit.components.v1 as components
import base64
import numpy as np
import time  # REM: æ™‚é–“è¨ˆæ¸¬ç”¨
from sqlalchemy import text
from sqlalchemy.exc import SQLAlchemyError

from src.config import DB_ENGINE, EMBEDDING_OPTIONS, LLM_ENGINE
from langchain_community.embeddings import OllamaEmbeddings
from sentence_transformers import SentenceTransformer

# REM: numpyé…åˆ—â†’pgvectorãƒªãƒ†ãƒ©ãƒ«
def to_pgvector_literal(vec):
    if isinstance(vec, np.ndarray):
        vec = vec.tolist()
    return "[" + ",".join(f"{float(x):.6f}" for x in vec) + "]"

# REM: LLM ã«ã‚ˆã‚‹è¦ç´„ï¼‹ä¸€è‡´åº¦ã‚¹ã‚³ã‚¢å–å¾—
def llm_summarize_with_score(query, content):
    prompt = f"""
ä»¥ä¸‹ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨æ–‡æ›¸ã®å†…å®¹ã§ã™ã€‚

ã€è³ªå•ã€‘
{query}

ã€æ–‡æ›¸ã€‘
{content[:3000]}

ã“ã®æ–‡æ›¸ãŒè³ªå•ã«ã©ã®ç¨‹åº¦ä¸€è‡´ã—ã¦ã„ã‚‹ã‹ï¼ˆ0.0ã€œ1.0ï¼‰ã§è©•ä¾¡ã—ã€æ¬¡ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

ä¸€è‡´åº¦: <score>
è¦ç´„: <summary>
""".strip()
    return_data = LLM_ENGINE.invoke(prompt)
    import re
    m = re.search(r"ä¸€è‡´åº¦[:ï¼š]\s*([0-9.]+).*?è¦ç´„[:ï¼š]\s*(.+)", return_data, re.DOTALL)
    if m:
        return m.group(2).strip(), float(m.group(1))
    return return_data.strip(), 0.0

# REM: ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ãƒ¢ãƒ¼ãƒ‰ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
def render_file_mode():
    # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ– ---
    if "history" not in st.session_state:
        st.session_state.history = []
    # --- è³ªå•å–å¾— ---
    query = st.session_state.query_input.strip()
    if not query:
        return

    # --- ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ†ãƒ¼ãƒ–ãƒ«åå–å¾— ---
    selected_key = st.session_state["selected_model_key"]
    selected_model = EMBEDDING_OPTIONS[selected_key]
    tablename = st.session_state["embedding_tablename"]

    # --- ãƒ‡ãƒãƒƒã‚°: ãƒ†ãƒ¼ãƒ–ãƒ«ä»¶æ•°ã¨ã‚¯ã‚¨ãƒªè¡¨ç¤º ---
    try:
        with DB_ENGINE.connect() as conn:
            cnt = conn.execute(text(f'SELECT COUNT(*) FROM "{tablename}"')).scalar()
        st.write(f"ğŸ” DEBUG â€” ãƒ†ãƒ¼ãƒ–ãƒ« {tablename} ã®ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {cnt} ä»¶")
        st.write(f"ğŸ” DEBUG â€” æ¤œç´¢ã‚¯ã‚¨ãƒª: â€œ{query}â€")
    except SQLAlchemyError as e:
        st.error(f"âŒ ãƒ†ãƒ¼ãƒ–ãƒ«ä»¶æ•°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        st.session_state.searching = False
        return

    # --- ã‚¯ã‚¨ãƒªåŸ‹ã‚è¾¼ã¿ï¼†ãƒ¬ã‚³ãƒ¼ãƒ‰å–å¾— ---
    start_ts = time.time()
    try:
        if selected_model["embedder"] == "OllamaEmbeddings":
            embedder = OllamaEmbeddings(
                model=selected_model["model_name"],
                base_url=selected_model.get("base_url")
            )
            query_embedding = embedder.embed_query(query)
        else:
            embedder = SentenceTransformer(selected_model["model_name"])
            query_embedding = embedder.encode([query], convert_to_numpy=True)[0]

        embedding_str = to_pgvector_literal(query_embedding)

        sql = f"""
            SELECT
                f.file_id,
                f.filename,
                c.refined_text   AS content,
                c.ocr_raw_text,
                c.quality_score,
                b.file_blob,
                MIN(e.embedding <-> '{embedding_str}'::vector) AS distance
            FROM "{tablename}" AS e
            JOIN file_contents AS c ON e.file_id = c.file_id
            JOIN files         AS f ON e.file_id = f.file_id
            JOIN file_blobs    AS b ON e.file_id = b.file_id
            GROUP BY f.file_id, f.filename, c.refined_text, c.ocr_raw_text, c.quality_score, b.file_blob
            ORDER BY distance ASC
            LIMIT 10
        """
        with DB_ENGINE.connect() as conn:
            rows = conn.execute(text(sql)).mappings().all()
    except SQLAlchemyError as e:
        st.error(f"âŒ æ¤œç´¢å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼: {e}")
        st.session_state.searching = False
        return

    # --- ã‚¼ãƒ­ä»¶ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° ---
    if not rows:
        st.warning("âš ï¸ è©²å½“ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.session_state.searching = False
        return

    # --- LLM è¦ç´„ï¼‹ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° ---
    summaries = []
    for row in rows:
        summary, score = llm_summarize_with_score(query, row["content"])
        summaries.append({
            "file_id": row["file_id"],
            "filename": row["filename"],
            "summary": summary,
            "score": score,
            "file_blob": row["file_blob"],
        })
    summaries.sort(key=lambda x: x["score"], reverse=True)

    # --- è¡¨ç¤º ---
    st.markdown("### ğŸ“‘ ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã®çµæœï¼ˆã‚¹ã‚³ã‚¢é †ï¼‰")
    for s in summaries:
        st.markdown(f"**ğŸ“„ {s['filename']}ï¼ˆä¸€è‡´åº¦: {s['score']:.2f}ï¼‰**")
        if s['filename'].lower().endswith(".pdf"):
            b64 = base64.b64encode(s["file_blob"]).decode("utf-8")
            iframe = (
                f'<iframe src="data:application/pdf;base64,{b64}" '
                'width="100%" height="600px" style="border:none;"></iframe>'
            )
            components.html(iframe, height=600)
            st.download_button(
                label=f"Download {s['filename']}",
                data=bytes(s["file_blob"]),
                file_name=s['filename'],
                mime="application/pdf",
                key=f"dl_{s['file_id']}"
            )
        st.write(s["summary"])
        if st.button("âœï¸ ç·¨é›†ã™ã‚‹", key=f"edit_{s['file_id']}"):
            st.session_state.edit_target_file_id = s["file_id"]
            st.session_state.mode = "ãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†"
            st.experimental_rerun()

    # --- å±¥æ­´ç™»éŒ²ï¼†ãƒ•ãƒ©ã‚°ãƒªã‚»ãƒƒãƒˆ ---
    elapsed = round(time.time() - start_ts, 2)
    response_text = "\n".join(s["summary"] for s in summaries)
    st.session_state.history.append({
        "query": query,
        "response": response_text,
        "model": selected_key,
        "time": elapsed
    })
    st.session_state.searching = False
