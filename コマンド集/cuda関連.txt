# Debian/Ubuntu ç³»ãªã‚‰
apt-get update && apt-get install -y procps

# Alpine ç³»ãªã‚‰
apk add --no-cache procps

# ãã®å¾Œ
watch -n 3 nvidia-smi


docker exec -it ollama bash


watch -n 3 nvidia-smi



docker exec -it ollama bash -c 'while true; do clear; nvidia-smi; sleep 3; done'




docker exec -it ollama watch -n 3 nvidia-smi
docker exec -it ollama bash -c 'while true; do clear; nvidia-smi; sleep 3; done'



# ragappå†…ã§cudaèªè­˜ã—ã¦ã‚‹ã®ã‹
docker exec -it ragapp bash
python3 -c "import torch; print(torch.cuda.is_available())"
# â†’ True ãŒå‡ºã‚Œã°å®Œç’§ã§ã™ğŸ’¯
